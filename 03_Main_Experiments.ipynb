{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the variables\n",
    "with open('./utils/variables.json', 'r') as file:\n",
    "    variables = json.load(file)\n",
    "\n",
    "SCR_feature_space = variables['SCR_feature_space']\n",
    "LAB_feature_space = variables['LAB_feature_space']\n",
    "train_len = variables['train_len']\n",
    "test_len = variables['test_len']\n",
    "print(len(SCR_feature_space), len(LAB_feature_space))\n",
    "print(train_len, test_len)\n",
    "\n",
    "# get num_processors for parallel computing\n",
    "num_processors = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figure_folder = \"Main_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read onset dadaset\n",
    "dataset = pd.read_csv(\"...\")\n",
    "# make sure the index is ordered\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "assert len(dataset) == train_len + test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the dataset into train and test\n",
    "data_train = dataset.iloc[:train_len, :].copy(deep = True)\n",
    "data_test = dataset.iloc[train_len:, :].copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run DTW with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since DTW-AROW does not require missing data imputation, we run it first. Then we impute the data and run normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Distance_Computing import parallel_distance_matrix\n",
    "from utils.Z_Helping_Functions import translate_dist_mtx_to_simi, fast_argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for SCR we do not apply the same normalization as SCR, since the values are already in the same range (unit)\n",
    "SCR_full = dataset.loc[:, SCR_feature_space].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCR_DTW_dist_full = parallel_distance_matrix(SCR_full, num_processors, get_DTW_distance)\n",
    "# np.save('/blue/yonghui.wu/lideyi/Personalization_Methodology/SCR_DTW_dist_imput2.npy', SCR_DTW_dist_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_dist_full = np.load('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transfrom distance mtx to similarity score mtx by min-max normalization and substration from 1\n",
    "SCR_DTW_simi_full = translate_dist_mtx_to_simi(SCR_DTW_dist_full)\n",
    "# sort similarity score mtx into idx matrix by most similar rank highest. This is for the entire dataset, train + test\n",
    "SCR_DTW_idx_full = fast_argsort(SCR_DTW_simi_full, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the similarity matrix and idx rankings only for train set, this is for the one-vs-all training\n",
    "SCR_DTW_dist_train = SCR_DTW_dist_full[:len(data_train), :len(data_train)]\n",
    "SCR_DTW_simi_train = translate_dist_mtx_to_simi(SCR_DTW_dist_train)\n",
    "SCR_DTW_idx_train = fast_argsort(SCR_DTW_simi_train, num_processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Missing Values in LAB and LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB: linear imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCR, since it just row wise we do not need to split into train and test\n",
    "SCR_full = SCR_full.interpolate(method='linear', axis = 1)\n",
    "SCR_full = SCR_full.bfill(axis=1)\n",
    "SCR_full = SCR_full.ffill(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# after imputation, we can safely split into train and test\n",
    "SCR_train = SCR_full.iloc[:train_len, :].copy(deep = True)\n",
    "SCR_test = SCR_full.iloc[train_len:, :].copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB: MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# it is of note that the imputation is done on the lab train and lab test separately\n",
    "# this is to avoid data leakage\n",
    "LAB_train = data_train.loc[:, LAB_feature_space].copy(deep = True)\n",
    "LAB_test = data_test.loc[:, LAB_feature_space].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lab normalization\n",
    "LAB_train = (LAB_train - LAB_train.min(skipna=True)) / (LAB_train.max(skipna=True) - LAB_train.min(skipna=True))\n",
    "LAB_test = (LAB_test - LAB_test.min(skipna=True)) / (LAB_test.max(skipna=True) - LAB_test.min(skipna=True))\n",
    "# impute lab missing values\n",
    "imputer = IterativeImputer(missing_values=np.nan, max_iter=1000, random_state=42)\n",
    "imputer.fit(LAB_train)\n",
    "LAB_train_temp = imputer.transform(LAB_train)\n",
    "LAB_test_temp = imputer.transform(LAB_test)\n",
    "LAB_train.loc[:, :] = LAB_train_temp\n",
    "LAB_test.loc[:, :] = LAB_test_temp\n",
    "# Concate train and test\n",
    "LAB_full = pd.concat([LAB_train, LAB_test], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Euclidean, Cosine and Manhattan Matrix of LAB and LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Distance_Computing import compute_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCR\n",
    "# Euclidean\n",
    "SCR_Euc_simi_full, SCR_Euc_idx_full, SCR_Euc_simi_train, SCR_Euc_idx_train = compute_similarity(SCR_full, 'euclidean', train_len, num_processors)\n",
    "# Cosine\n",
    "SCR_Cos_simi_full, SCR_Cos_idx_full, SCR_Cos_simi_train, SCR_Cos_idx_train = compute_similarity(SCR_full, 'cosine', train_len, num_processors)\n",
    "# Manhattan\n",
    "SCR_Manh_simi_full, SCR_Manh_idx_full, SCR_Manh_simi_train, SCR_Manh_idx_train = compute_similarity(SCR_full, 'manhattan', train_len, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LAB\n",
    "# Euclidean\n",
    "LAB_Euc_simi_full, LAB_Euc_idx_full, LAB_Euc_simi_train, LAB_Euc_idx_train = compute_similarity(LAB_full, 'euclidean', train_len, num_processors)\n",
    "# Cosine\n",
    "LAB_Cos_simi_full, LAB_Cos_idx_full, LAB_Cos_simi_train, LAB_Cos_idx_train = compute_similarity(LAB_full, 'cosine', train_len, num_processors)\n",
    "# Manhattan\n",
    "LAB_Manh_simi_full, LAB_Manh_idx_full, LAB_Manh_simi_train, LAB_Manh_idx_train = compute_similarity(LAB_full, 'manhattan', train_len, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simi here is the un-ordered, normalized similarity score matrix, idx is the ordered paitent index matrix\n",
    "# nw stands for not weighted by data overlap rates matrix\n",
    "nw_fea_arrs_dict = {\"SCR\": {\"DTW\": {\"simi\": {\"full\": SCR_DTW_simi_full, \"train\": SCR_DTW_simi_train}, \"idx\": {\"full\": SCR_DTW_idx_full, \"train\": SCR_DTW_idx_train}}, \n",
    "                            \"Euc\": {\"simi\": {\"full\": SCR_Euc_simi_full, \"train\": SCR_Euc_simi_train}, \"idx\": {\"full\": SCR_Euc_idx_full, \"train\": SCR_Euc_idx_train}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": SCR_Cos_simi_full, \"train\": SCR_Cos_simi_train}, \"idx\": {\"full\": SCR_Cos_idx_full, \"train\": SCR_Cos_idx_train}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": SCR_Manh_simi_full, \"train\": SCR_Manh_simi_train}, \"idx\": {\"full\": SCR_Manh_idx_full, \"train\": SCR_Manh_idx_train}}}, \n",
    "                    \"LAB\": {\"Euc\": {\"simi\": {\"full\": LAB_Euc_simi_full, \"train\": LAB_Euc_simi_train}, \"idx\": {\"full\": LAB_Euc_idx_full, \"train\": LAB_Euc_idx_train}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": LAB_Cos_simi_full, \"train\": LAB_Cos_simi_train}, \"idx\": {\"full\": LAB_Cos_idx_full, \"train\": LAB_Cos_idx_train}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": LAB_Manh_simi_full, \"train\": LAB_Manh_simi_train}, \"idx\": {\"full\": LAB_Manh_idx_full, \"train\": LAB_Manh_idx_train}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overlap Rates Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read pre-computed pairwise data overlap rates\n",
    "SCR_overlap_full = np.load('...')\n",
    "LAB_overlap_full = np.load('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# consequently, we will only use the upper-left block of the overlap rate mtx for one-vs-all training\n",
    "SCR_overlap_train = SCR_overlap_full[:train_len, :train_len]\n",
    "LAB_overlap_train = LAB_overlap_full[:train_len, :train_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Distance_Computing import overlap_rates_weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# on full data (for testing)\n",
    "# SCR\n",
    "SCR_DTW_simi_wt_full, SCR_DTW_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"DTW\"][\"simi\"][\"full\"], num_processors)\n",
    "SCR_Euc_simi_wt_full, SCR_Euc_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"Euc\"][\"simi\"][\"full\"], num_processors)\n",
    "SCR_Cos_simi_wt_full, SCR_Cos_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"Cos\"][\"simi\"][\"full\"], num_processors)\n",
    "SCR_Manh_simi_wt_full, SCR_Manh_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"Manh\"][\"simi\"][\"full\"], num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LAB\n",
    "LAB_Euc_simi_wt_full, LAB_Euc_idx_wt_full = overlap_rates_weighting(LAB_overlap_full, nw_fea_arrs_dict[\"LAB\"][\"Euc\"][\"simi\"][\"full\"], num_processors)\n",
    "LAB_Cos_simi_wt_full, LAB_Cos_idx_wt_full = overlap_rates_weighting(LAB_overlap_full, nw_fea_arrs_dict[\"LAB\"][\"Cos\"][\"simi\"][\"full\"], num_processors)\n",
    "LAB_Manh_simi_wt_full, LAB_Manh_idx_wt_full = overlap_rates_weighting(LAB_overlap_full, nw_fea_arrs_dict[\"LAB\"][\"Manh\"][\"simi\"][\"full\"], num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# on training data (for one-vs-all training)\n",
    "# SCR\n",
    "SCR_DTW_simi_wt_train, SCR_DTW_idx_wt_train = overlap_rates_weighting(SCR_overlap_train, nw_fea_arrs_dict[\"SCR\"][\"DTW\"][\"simi\"][\"train\"], num_processors)\n",
    "SCR_Euc_simi_wt_train, SCR_Euc_idx_wt_train = overlap_rates_weighting(SCR_overlap_train, nw_fea_arrs_dict[\"SCR\"][\"Euc\"][\"simi\"][\"train\"], num_processors)\n",
    "SCR_Cos_simi_wt_train, SCR_Cos_idx_wt_train = overlap_rates_weighting(SCR_overlap_train, nw_fea_arrs_dict[\"SCR\"][\"Cos\"][\"simi\"][\"train\"], num_processors)\n",
    "SCR_Manh_simi_wt_train, SCR_Manh_idx_wt_train = overlap_rates_weighting(SCR_overlap_train, nw_fea_arrs_dict[\"SCR\"][\"Manh\"][\"simi\"][\"train\"], num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LAB\n",
    "LAB_Euc_simi_wt_train, LAB_Euc_idx_wt_train = overlap_rates_weighting(LAB_overlap_train, nw_fea_arrs_dict[\"LAB\"][\"Euc\"][\"simi\"][\"train\"], num_processors)\n",
    "LAB_Cos_simi_wt_train, LAB_Cos_idx_wt_train = overlap_rates_weighting(LAB_overlap_train, nw_fea_arrs_dict[\"LAB\"][\"Cos\"][\"simi\"][\"train\"], num_processors)\n",
    "LAB_Manh_simi_wt_train, LAB_Manh_idx_wt_train = overlap_rates_weighting(LAB_overlap_train, nw_fea_arrs_dict[\"LAB\"][\"Manh\"][\"simi\"][\"train\"], num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simi here is the un-ordered, normalized similarity score matrix, idx is the ordered paitent index matrix\n",
    "# nw stands for not weighted by data overlap rates matrix\n",
    "wt_fea_arrs_dict = {\"SCR\": {\"DTW\": {\"simi\": {\"full\": SCR_DTW_simi_wt_full, \"train\": SCR_DTW_simi_wt_train}, \"idx\": {\"full\": SCR_DTW_idx_wt_full, \"train\": SCR_DTW_idx_wt_train}}, \n",
    "                            \"Euc\": {\"simi\": {\"full\": SCR_Euc_simi_wt_full, \"train\": SCR_Euc_simi_wt_train}, \"idx\": {\"full\": SCR_Euc_idx_wt_full, \"train\": SCR_Euc_idx_wt_train}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": SCR_Cos_simi_wt_full, \"train\": SCR_Cos_simi_wt_train}, \"idx\": {\"full\": SCR_Cos_idx_wt_full, \"train\": SCR_Cos_idx_wt_train}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": SCR_Manh_simi_wt_full, \"train\": SCR_Manh_simi_wt_train}, \"idx\": {\"full\": SCR_Manh_idx_wt_full, \"train\": SCR_Manh_idx_wt_train}}}, \n",
    "                    \"LAB\": {\"Euc\": {\"simi\": {\"full\": LAB_Euc_simi_wt_full, \"train\": LAB_Euc_simi_wt_train}, \"idx\": {\"full\": LAB_Euc_idx_wt_full, \"train\": LAB_Euc_idx_wt_train}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": LAB_Cos_simi_wt_full, \"train\": LAB_Cos_simi_wt_train}, \"idx\": {\"full\": LAB_Cos_idx_wt_full, \"train\": LAB_Cos_idx_wt_train}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": LAB_Manh_simi_wt_full, \"train\": LAB_Manh_simi_wt_train}, \"idx\": {\"full\": LAB_Manh_idx_wt_full, \"train\": LAB_Manh_idx_wt_train}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Distance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neighborhood sizes for optimizing best distance measures\n",
    "k_sizes_train = [i for i in range(10, 201, 5)]\n",
    "print(len(k_sizes_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate simi_dict for one-vs-all val\n",
    "def process_idx_arr_for_optimizing(idx_arr: np.array, y_train: np.array) -> tuple[np.array, np.array]:\n",
    "    idx_arr_clean = remove_row_idx(idx_arr)\n",
    "    y_train_arr = sort_by_idx_arr(idx_arr_clean, y_train)\n",
    "    return idx_arr_clean, y_train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_row_idx(idx_arr: np.array) -> np.array:    \n",
    "    # Create a list to hold the new rows\n",
    "    idx_arr_clean = []\n",
    "    \n",
    "    # Iterate through each row in the matrix\n",
    "    for row_index in range(idx_arr.shape[0]):\n",
    "        # Get the current row\n",
    "        row = idx_arr[row_index]\n",
    "        # Create a new row excluding the element equal to the row index\n",
    "        new_row = row[row != row_index]\n",
    "        # Append the new row to the new_matrix list\n",
    "        idx_arr_clean.append(new_row)\n",
    "    \n",
    "    # Convert the list of rows back to a NumPy array\n",
    "    idx_arr_clean = np.array(idx_arr_clean)\n",
    "    \n",
    "    return idx_arr_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sort_by_idx_arr(idx_arr: np.array, y_train: np.array) -> np.array:\n",
    "    y_train_arr = np.tile(y_train, (idx_arr.shape[0], 1))\n",
    "    # Use advanced indexing to select the elements from matrix_b\n",
    "    row_indices = np.arange(idx_arr.shape[0])[:, None]  # Create an array of row indices\n",
    "    y_train_arr = y_train_arr[row_indices, idx_arr]  # Use the row indices and matrix_a for advanced indexing\n",
    "    \n",
    "    return y_train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_idx = list(data_train.index)\n",
    "test_idx = list(data_test.index)\n",
    "y_train = np.array(data_train[\"AKI_LABEL\"])\n",
    "y_test = np.array(data_test[\"AKI_LABEL\"])\n",
    "y_full = np.array(dataset[\"AKI_LABEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the similarity score array into array that can be used for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCR\n",
    "SCR_idx_y_nw_dict_train = {}\n",
    "SCR_idx_y_wt_dict_train = {}\n",
    "\n",
    "for dist_measure, arrs in tqdm(nw_fea_arrs_dict[\"SCR\"].items()):\n",
    "    idx_arr_train_clean, y_train_arr = process_idx_arr_for_optimizing(arrs[\"idx\"][\"train\"], y_train)\n",
    "    SCR_idx_y_nw_dict_train[dist_measure] = {\"idx\": idx_arr_train_clean, \"label\": y_train_arr}\n",
    "for dist_measure, arrs in tqdm(wt_fea_arrs_dict[\"SCR\"].items()):\n",
    "    idx_arr_train_clean, y_train_arr = process_idx_arr_for_optimizing(arrs[\"idx\"][\"train\"], y_train)\n",
    "    SCR_idx_y_wt_dict_train[dist_measure] = {\"idx\": idx_arr_train_clean, \"label\": y_train_arr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lab\n",
    "LAB_idx_y_nw_dict_train = {}\n",
    "LAB_idx_y_wt_dict_train = {}\n",
    "\n",
    "for dist_measure, arrs in tqdm(nw_fea_arrs_dict[\"LAB\"].items()):\n",
    "    idx_arr_train_clean, y_train_arr = process_idx_arr_for_optimizing(arrs[\"idx\"][\"train\"], y_train)\n",
    "    LAB_idx_y_nw_dict_train[dist_measure] = {\"idx\": idx_arr_train_clean, \"label\": y_train_arr}\n",
    "for dist_measure, arrs in tqdm(wt_fea_arrs_dict[\"LAB\"].items()):\n",
    "    idx_arr_train_clean, y_train_arr = process_idx_arr_for_optimizing(arrs[\"idx\"][\"train\"], y_train)\n",
    "    LAB_idx_y_wt_dict_train[dist_measure] = {\"idx\": idx_arr_train_clean, \"label\": y_train_arr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize distance measure at each k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Testing import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_distance_measures(clean_arrs_dict: dict, y_test: np.array, k_sizes: int) -> dict:\n",
    "    \n",
    "    best_method_each_k = {\"name\": [], \"AUPRC\": []}\n",
    "    \n",
    "    for k in tqdm(k_sizes):\n",
    "        \n",
    "        best_method_name = ''\n",
    "        best_method_AUPRC = 0\n",
    "        \n",
    "        for name, arr_dict in clean_arrs_dict.items():\n",
    "            AUPRC, _ = KNN(arr_dict, k, y_test)\n",
    "            \n",
    "            # if better AUPRC, update\n",
    "            if AUPRC > best_method_AUPRC:\n",
    "                best_method_name = name\n",
    "                best_method_AUPRC = AUPRC\n",
    "                \n",
    "        best_method_each_k[\"name\"].append(best_method_name)\n",
    "        best_method_each_k[\"AUPRC\"].append(best_method_AUPRC)\n",
    "    \n",
    "    return best_method_each_k    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a table to track all performance\n",
    "# NW is not overlap rates weighting\n",
    "# WT is overlap rates weighting\n",
    "grid_search_table = pd.DataFrame('', index = k_sizes_train, columns = [\"SCR NW\", \"LAB NW\", \"SCR WT\", \"LAB WT\"])\n",
    "grid_search_table.index.name = \"k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_nw = compare_distance_measures(SCR_idx_y_nw_dict_train, y_train, k_sizes_train)\n",
    "SCR_wt = compare_distance_measures(SCR_idx_y_wt_dict_train, y_train, k_sizes_train)\n",
    "LAB_nw = compare_distance_measures(LAB_idx_y_nw_dict_train, y_train, k_sizes_train)\n",
    "LAB_wt = compare_distance_measures(LAB_idx_y_wt_dict_train, y_train, k_sizes_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_table.loc[:, \"SCR NW\"] = SCR_nw[\"name\"]\n",
    "grid_search_table.loc[:, \"SCR WT\"] = SCR_wt[\"name\"]\n",
    "grid_search_table.loc[:, \"LAB NW\"] = LAB_nw[\"name\"]\n",
    "grid_search_table.loc[:, \"LAB WT\"] = LAB_wt[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To facilitate computing, we do not use the idea of unique distance measure for each k\n",
    "# instead one metric for one condition. We use the metric that previal in the column\n",
    "best_distance_measures = dict()\n",
    "for column in grid_search_table.columns:\n",
    "    mode_value = grid_search_table[column].mode()[0]\n",
    "    best_distance_measures[column] = mode_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Best Distance Measures on Test Set Using KNN/LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the similarity score array into array that can be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Testing import process_idx_arr_for_test, evluate_on_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCR\n",
    "SCR_idx_y_nw_dict_test = {}\n",
    "SCR_idx_y_wt_dict_test = {}\n",
    "\n",
    "for dist_measure, arrs in tqdm(nw_fea_arrs_dict[\"SCR\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    SCR_idx_y_nw_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}\n",
    "for dist_measure, arrs in tqdm(wt_fea_arrs_dict[\"SCR\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    SCR_idx_y_wt_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LAB\n",
    "LAB_idx_y_nw_dict_test = {}\n",
    "LAB_idx_y_wt_dict_test = {}\n",
    "\n",
    "for dist_measure, arrs in tqdm(nw_fea_arrs_dict[\"LAB\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    LAB_idx_y_nw_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}\n",
    "for dist_measure, arrs in tqdm(wt_fea_arrs_dict[\"LAB\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    LAB_idx_y_wt_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance by using KNN/LR as the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we reduce the number of k to be tested\n",
    "k_sizes_test = [i for i in range(10, 201, 10)]\n",
    "print(len(k_sizes_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save necessary materials for sensitivity analysis: nw_fea_arrs_dict (only full and simi), SCR_train, SCR_test, LAB_train, LAB_test, y_test, k_sizes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nw_fea_arrs_dict_for_save = {\n",
    "    \"SCR\": {\"DTW\": {\"simi\": {\"full\": SCR_DTW_simi_full}}, \n",
    "            \"Euc\": {\"simi\": {\"full\": SCR_Euc_simi_full}}, \n",
    "            \"Cos\": {\"simi\": {\"full\": SCR_Cos_simi_full}}, \n",
    "            \"Manh\":{\"simi\": {\"full\": SCR_Manh_simi_full}}}, \n",
    "    \"LAB\": {\"Euc\": {\"simi\": {\"full\": LAB_Euc_simi_full}}, \n",
    "            \"Cos\": {\"simi\": {\"full\": LAB_Cos_simi_full}}, \n",
    "            \"Manh\":{\"simi\": {\"full\": LAB_Manh_simi_full}}},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "varables_for_save = {\n",
    "    \"nw_fea_arrs_dict\": nw_fea_arrs_dict_for_save,\n",
    "    \"SCR_train\": SCR_train,\n",
    "    \"SCR_test\": SCR_test,\n",
    "    \"LAB_train\": LAB_train,\n",
    "    \"LAB_test\": LAB_test,\n",
    "    \"y_test\": y_test,\n",
    "    'y_full': y_full,\n",
    "    \"k_sizes_test\": k_sizes_test,\n",
    "    'train_idx': train_idx,\n",
    "    'test_idx': test_idx,\n",
    "}\n",
    "# Save all objects to a file\n",
    "with open('...', 'wb') as file:\n",
    "    pickle.dump(varables_for_save, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main evaluation of overlap rates weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_control_KNN, _ = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"DTW\", \"Euc\", \n",
    "                                             y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                             LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_control_LR, _ = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"DTW\", \"Euc\", \n",
    "                                             y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                             LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Euc_control_KNN, LAB_Euc_control_KNN = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Euc\", \"Euc\", y_test, k_sizes_test, \n",
    "                                                               SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                               LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Euc_control_LR, LAB_Euc_control_LR = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Euc\", \"Euc\", \n",
    "                                                             y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                             LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Cos_control_KNN, LAB_Cos_control_KNN = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Cos\", \"Cos\", \n",
    "                                                               y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                               LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Cos_control_LR, LAB_Cos_control_LR = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Cos\", \"Cos\", \n",
    "                                                               y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                               LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Manh_control_KNN, LAB_Manh_control_KNN = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Manh\", \"Manh\", \n",
    "                                                                 y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                                 LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Manh_control_LR, LAB_Manh_control_LR = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Manh\", \"Manh\", \n",
    "                                                                y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                                LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NW_WT_performace_results = {\n",
    "    \"SCR_DTW_control_KNN\": SCR_DTW_control_KNN,\n",
    "    \"SCR_DTW_control_LR\": SCR_DTW_control_LR,\n",
    "    \"SCR_Euc_control_KNN\": SCR_Euc_control_KNN,\n",
    "    \"LAB_Euc_control_KNN\": LAB_Euc_control_KNN,\n",
    "    \"SCR_Euc_control_LR\": SCR_Euc_control_LR,\n",
    "    \"LAB_Euc_control_LR\": LAB_Euc_control_LR,\n",
    "    \"SCR_Cos_control_KNN\": SCR_Cos_control_KNN,\n",
    "    \"LAB_Cos_control_KNN\": LAB_Cos_control_KNN,\n",
    "    \"SCR_Cos_control_LR\": SCR_Cos_control_LR,\n",
    "    \"LAB_Cos_control_LR\": LAB_Cos_control_LR,\n",
    "    \"SCR_Manh_control_KNN\": SCR_Manh_control_KNN,\n",
    "    \"LAB_Manh_control_KNN\": LAB_Manh_control_KNN,\n",
    "    \"SCR_Manh_control_LR\": SCR_Manh_control_LR,\n",
    "    \"LAB_Manh_control_LR\": LAB_Manh_control_LR,\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"./Results_dict/Main_results/NW_WT_performace_results.json\", \"w\") as json_file:\n",
    "    json.dump(NW_WT_performace_results, json_file, indent=4)  # Use indent for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot and Prove: Data Overlap Rates Weighting can Improve Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Plotting import plot_metric_along_k, add_subplot_index, save_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Results_dict/Main_results/NW_WT_performace_results.json\", \"r\") as json_file:\n",
    "    NW_WT_performace_results = json.load(json_file)\n",
    "SCR_DTW_control_KNN = NW_WT_performace_results[\"SCR_DTW_control_KNN\"]  \n",
    "SCR_DTW_control_LR = NW_WT_performace_results[\"SCR_DTW_control_LR\"]  \n",
    "SCR_Euc_control_KNN = NW_WT_performace_results[\"SCR_Euc_control_KNN\"]  \n",
    "LAB_Euc_control_KNN = NW_WT_performace_results[\"LAB_Euc_control_KNN\"]  \n",
    "SCR_Euc_control_LR = NW_WT_performace_results[\"SCR_Euc_control_LR\"]  \n",
    "LAB_Euc_control_LR = NW_WT_performace_results[\"LAB_Euc_control_LR\"]  \n",
    "SCR_Cos_control_KNN = NW_WT_performace_results[\"SCR_Cos_control_KNN\"]  \n",
    "LAB_Cos_control_KNN = NW_WT_performace_results[\"LAB_Cos_control_KNN\"]  \n",
    "SCR_Cos_control_LR = NW_WT_performace_results[\"SCR_Cos_control_LR\"]  \n",
    "LAB_Cos_control_LR = NW_WT_performace_results[\"LAB_Cos_control_LR\"]\n",
    "SCR_Manh_control_KNN = NW_WT_performace_results[\"SCR_Manh_control_KNN\"]\n",
    "LAB_Manh_control_KNN = NW_WT_performace_results[\"LAB_Manh_control_KNN\"]\n",
    "SCR_Manh_control_LR = NW_WT_performace_results[\"SCR_Manh_control_LR\"]\n",
    "LAB_Manh_control_LR = NW_WT_performace_results[\"LAB_Manh_control_LR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_KNN[\"NW\"][metric], SCR_DTW_control_KNN[\"WT\"][metric], \"SCr-KNN, DTW-AROW: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_KNN[\"NW\"][metric], SCR_Euc_control_KNN[\"WT\"][metric], \"SCr-KNN, Euclidean: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_KNN[\"NW\"][metric], SCR_Cos_control_KNN[\"WT\"][metric], \"SCr-KNN, Cosine: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_KNN[\"NW\"][metric], SCR_Manh_control_KNN[\"WT\"][metric], \"SCr-KNN, Manhattan: %s\"%(metric), metric, 'KNN')\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-KNN-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_KNN[\"NW\"][metric], SCR_DTW_control_KNN[\"WT\"][metric], \"SCr-KNN, DTW-AROW: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_KNN[\"NW\"][metric], SCR_Euc_control_KNN[\"WT\"][metric], \"SCr-KNN, Euclidean: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_KNN[\"NW\"][metric], SCR_Cos_control_KNN[\"WT\"][metric], \"SCr-KNN, Cosine: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_KNN[\"NW\"][metric], SCR_Manh_control_KNN[\"WT\"][metric], \"SCr-KNN, Manhattan: %s\"%(metric), metric, 'KNN')\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-KNN-AUROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_LR[\"NW\"][metric], SCR_DTW_control_LR[\"WT\"][metric], \"SCr-LR, DTW-AROW: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_LR[\"NW\"][metric], SCR_Euc_control_LR[\"WT\"][metric], \"SCr-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_LR[\"NW\"][metric], SCR_Cos_control_LR[\"WT\"][metric], \"SCr-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_LR[\"NW\"][metric], SCR_Manh_control_LR[\"WT\"][metric], \"SCr-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-LR-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_LR[\"NW\"][metric], SCR_DTW_control_LR[\"WT\"][metric], \"SCr-LR, DTW-AROW: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_LR[\"NW\"][metric], SCR_Euc_control_LR[\"WT\"][metric], \"SCr-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_LR[\"NW\"][metric], SCR_Cos_control_LR[\"WT\"][metric], \"SCr-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_LR[\"NW\"][metric], SCR_Manh_control_LR[\"WT\"][metric], \"SCr-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-LR-AUROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_KNN[\"NW\"][metric], LAB_Euc_control_KNN[\"WT\"][metric], \"Lab-KNN, Euclidean: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_KNN[\"NW\"][metric], LAB_Cos_control_KNN[\"WT\"][metric], \"Lab-KNN, Cosine: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_KNN[\"NW\"][metric], LAB_Manh_control_KNN[\"WT\"][metric], \"Lab-KNN, Manhattan: %s\"%(metric), metric, \"KNN\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-KNN-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_KNN[\"NW\"][metric], LAB_Euc_control_KNN[\"WT\"][metric], \"Lab-KNN, Euclidean: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_KNN[\"NW\"][metric], LAB_Cos_control_KNN[\"WT\"][metric], \"Lab-KNN, Cosine: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_KNN[\"NW\"][metric], LAB_Manh_control_KNN[\"WT\"][metric], \"Lab-KNN, Manhattan: %s\"%(metric), metric, \"KNN\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-KNN-AUROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_LR[\"NW\"][metric], LAB_Euc_control_LR[\"WT\"][metric], \"Lab-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_LR[\"NW\"][metric], LAB_Cos_control_LR[\"WT\"][metric], \"Lab-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_LR[\"NW\"][metric], LAB_Manh_control_LR[\"WT\"][metric], \"Lab-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-LR-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_LR[\"NW\"][metric], LAB_Euc_control_LR[\"WT\"][metric], \"Lab-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_LR[\"NW\"][metric], LAB_Cos_control_LR[\"WT\"][metric], \"Lab-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_LR[\"NW\"][metric], LAB_Manh_control_LR[\"WT\"][metric], \"Lab-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-LR-AUROC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot and Prove: Distance Measure Optimization can Improve Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Plotting import plot_optim_vs_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_nw_control_AUPRCs_KNN = [SCR_DTW_control_KNN[\"NW\"][\"AUPRC\"], SCR_Euc_control_KNN[\"NW\"][\"AUPRC\"],\n",
    "                        SCR_Cos_control_KNN[\"NW\"][\"AUPRC\"], SCR_Manh_control_KNN[\"NW\"][\"AUPRC\"]]\n",
    "SCR_nw_control_AUROCs_KNN = [SCR_DTW_control_KNN[\"NW\"][\"AUROC\"], SCR_Euc_control_KNN[\"NW\"][\"AUROC\"],\n",
    "                        SCR_Cos_control_KNN[\"NW\"][\"AUROC\"], SCR_Manh_control_KNN[\"NW\"][\"AUROC\"]]\n",
    "SCR_wt_control_AUPRCs_KNN = [SCR_DTW_control_KNN[\"WT\"][\"AUPRC\"], SCR_Euc_control_KNN[\"WT\"][\"AUPRC\"],\n",
    "                        SCR_Cos_control_KNN[\"WT\"][\"AUPRC\"], SCR_Manh_control_KNN[\"WT\"][\"AUPRC\"]]\n",
    "SCR_wt_control_AUROCs_KNN = [SCR_DTW_control_KNN[\"WT\"][\"AUROC\"], SCR_Euc_control_KNN[\"WT\"][\"AUROC\"],\n",
    "                        SCR_Cos_control_KNN[\"WT\"][\"AUROC\"], SCR_Manh_control_KNN[\"WT\"][\"AUROC\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_nw_control_AUPRCs_LR = [SCR_DTW_control_LR[\"NW\"][\"AUPRC\"], SCR_Euc_control_LR[\"NW\"][\"AUPRC\"],\n",
    "                        SCR_Cos_control_LR[\"NW\"][\"AUPRC\"], SCR_Manh_control_LR[\"NW\"][\"AUPRC\"]]\n",
    "SCR_nw_control_AUROCs_LR = [SCR_DTW_control_LR[\"NW\"][\"AUROC\"], SCR_Euc_control_LR[\"NW\"][\"AUROC\"],\n",
    "                        SCR_Cos_control_LR[\"NW\"][\"AUROC\"], SCR_Manh_control_LR[\"NW\"][\"AUROC\"]]\n",
    "SCR_wt_control_AUPRCs_LR = [SCR_DTW_control_LR[\"WT\"][\"AUPRC\"], SCR_Euc_control_LR[\"WT\"][\"AUPRC\"],\n",
    "                        SCR_Cos_control_LR[\"WT\"][\"AUPRC\"], SCR_Manh_control_LR[\"WT\"][\"AUPRC\"]]\n",
    "SCR_wt_control_AUROCs_LR = [SCR_DTW_control_LR[\"WT\"][\"AUROC\"], SCR_Euc_control_LR[\"WT\"][\"AUROC\"],\n",
    "                        SCR_Cos_control_LR[\"WT\"][\"AUROC\"], SCR_Manh_control_LR[\"WT\"][\"AUROC\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8))\n",
    "\n",
    "plot_optim_vs_controls(axs[0, 0], k_sizes_test, SCR_nw_control_AUPRCs_KNN, [\"DTW\", \"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"SCR NW\"], 'SCr-KNN (w/o OW)', 'AUPRC')\n",
    "plot_optim_vs_controls(axs[0, 1], k_sizes_test, SCR_nw_control_AUROCs_KNN, [\"DTW\", \"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"SCR NW\"], 'SCr-KNN (w/o OW)', 'AUROC')\n",
    "plot_optim_vs_controls(axs[1, 0], k_sizes_test, SCR_wt_control_AUPRCs_KNN, [\"DTW\", \"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"SCR WT\"],'SCr-KNN (w/ OW)', 'AUPRC')\n",
    "plot_optim_vs_controls(axs[1, 1], k_sizes_test, SCR_wt_control_AUROCs_KNN, [\"DTW\", \"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"SCR WT\"],'SCr-KNN (w/ OW)', 'AUROC')\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-KNN-distance-measure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8))\n",
    "\n",
    "plot_optim_vs_controls(axs[0, 0], k_sizes_test, SCR_nw_control_AUPRCs_LR, [\"DTW\", \"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"SCR NW\"], 'SCr-LR (w/o OW)', 'AUPRC')\n",
    "plot_optim_vs_controls(axs[0, 1], k_sizes_test, SCR_nw_control_AUROCs_LR, [\"DTW\", \"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"SCR NW\"], 'SCr-LR (w/o OW)', 'AUROC')\n",
    "plot_optim_vs_controls(axs[1, 0], k_sizes_test, SCR_wt_control_AUPRCs_LR, [\"DTW\", \"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"SCR WT\"],'SCr-LR (w/ OW), Weighting', 'AUPRC')\n",
    "plot_optim_vs_controls(axs[1, 1], k_sizes_test, SCR_wt_control_AUROCs_LR, [\"DTW\", \"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"SCR WT\"],'SCr-LR (w/ OW), Weighting', 'AUROC')\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-LR-distance-measure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_nw_control_AUPRCs_KNN = [LAB_Euc_control_KNN[\"NW\"][\"AUPRC\"], LAB_Cos_control_KNN[\"NW\"][\"AUPRC\"], LAB_Manh_control_KNN[\"NW\"][\"AUPRC\"]]\n",
    "LAB_nw_control_AUROCs_KNN = [LAB_Euc_control_KNN[\"NW\"][\"AUROC\"], LAB_Cos_control_KNN[\"NW\"][\"AUROC\"], LAB_Manh_control_KNN[\"NW\"][\"AUROC\"]]\n",
    "LAB_wt_control_AUPRCs_KNN = [LAB_Euc_control_KNN[\"WT\"][\"AUPRC\"], LAB_Cos_control_KNN[\"WT\"][\"AUPRC\"], LAB_Manh_control_KNN[\"WT\"][\"AUPRC\"]]\n",
    "LAB_wt_control_AUROCs_KNN = [LAB_Euc_control_KNN[\"WT\"][\"AUROC\"], LAB_Cos_control_KNN[\"WT\"][\"AUROC\"], LAB_Manh_control_KNN[\"WT\"][\"AUROC\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_nw_control_AUPRCs_LR = [LAB_Euc_control_LR[\"NW\"][\"AUPRC\"], LAB_Cos_control_LR[\"NW\"][\"AUPRC\"], LAB_Manh_control_LR[\"NW\"][\"AUPRC\"]]\n",
    "LAB_nw_control_AUROCs_LR = [LAB_Euc_control_LR[\"NW\"][\"AUROC\"], LAB_Cos_control_LR[\"NW\"][\"AUROC\"], LAB_Manh_control_LR[\"NW\"][\"AUROC\"]]\n",
    "LAB_wt_control_AUPRCs_LR = [LAB_Euc_control_LR[\"WT\"][\"AUPRC\"], LAB_Cos_control_LR[\"WT\"][\"AUPRC\"], LAB_Manh_control_LR[\"WT\"][\"AUPRC\"]]\n",
    "LAB_wt_control_AUROCs_LR = [LAB_Euc_control_LR[\"WT\"][\"AUROC\"], LAB_Cos_control_LR[\"WT\"][\"AUROC\"], LAB_Manh_control_LR[\"WT\"][\"AUROC\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8))\n",
    "\n",
    "plot_optim_vs_controls(axs[0, 0], k_sizes_test, LAB_nw_control_AUPRCs_KNN, [\"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"LAB NW\"], 'Lab-KNN (w/o OW)', 'AUPRC')\n",
    "plot_optim_vs_controls(axs[0, 1], k_sizes_test, LAB_nw_control_AUROCs_KNN, [\"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"LAB NW\"], 'Lab-KNN (w/o OW)', 'AUROC')\n",
    "plot_optim_vs_controls(axs[1, 0], k_sizes_test, LAB_wt_control_AUPRCs_KNN, [\"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"LAB WT\"],'Lab-KNN (w/ OW)', 'AUPRC')\n",
    "plot_optim_vs_controls(axs[1, 1], k_sizes_test, LAB_wt_control_AUROCs_KNN, [\"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"LAB WT\"],'Lab-KNN (w/ OW)', 'AUROC')\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-KNN-distance-measure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8))\n",
    "\n",
    "plot_optim_vs_controls(axs[0, 0], k_sizes_test, LAB_nw_control_AUPRCs_LR, [\"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"LAB NW\"], 'Lab-LR (w/o OW)', 'AUPRC')\n",
    "plot_optim_vs_controls(axs[0, 1], k_sizes_test, LAB_nw_control_AUROCs_LR, [\"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"LAB NW\"], 'Lab-LR (w/o OW)', 'AUROC')\n",
    "plot_optim_vs_controls(axs[1, 0], k_sizes_test, LAB_wt_control_AUPRCs_LR, [\"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"LAB WT\"],'Lab-LR (w/ OW)', 'AUPRC')\n",
    "plot_optim_vs_controls(axs[1, 1], k_sizes_test, LAB_wt_control_AUROCs_LR, [\"Euc\", \"Cos\", \"Manh\"], \n",
    "                                best_distance_measures[\"LAB WT\"],'Lab-LR (w/ OW)', 'AUROC')\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-LR-distance-measure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Feature Type Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt_SCR_simi_nw_train = nw_fea_arrs_dict[\"SCR\"][best_distance_measures[\"SCR NW\"]][\"simi\"][\"train\"]\n",
    "opt_LAB_simi_nw_train = nw_fea_arrs_dict[\"LAB\"][best_distance_measures[\"LAB NW\"]][\"simi\"][\"train\"]\n",
    "opt_SCR_simi_wt_train = wt_fea_arrs_dict[\"SCR\"][best_distance_measures[\"SCR WT\"]][\"simi\"][\"train\"]\n",
    "opt_LAB_simi_wt_train = wt_fea_arrs_dict[\"LAB\"][best_distance_measures[\"LAB WT\"]][\"simi\"][\"train\"]\n",
    "\n",
    "opt_measure_simi_nw_train_dict = {\"SCR\": opt_SCR_simi_nw_train, \"LAB\": opt_LAB_simi_nw_train}\n",
    "opt_measure_simi_wt_train_dict = {\"SCR\": opt_SCR_simi_wt_train, \"LAB\": opt_LAB_simi_wt_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get feature type weight combination\n",
    "# A is for weighting SCR, B is for LAB\n",
    "weight_combines = []\n",
    "for A in np.arange(0.1, 1.1, 0.1):\n",
    "    for B in np.arange(0.1, 1.1, 0.1):\n",
    "        if A + B == 1:\n",
    "            weight_combines.append((round(A, 1), round(B, 1)))  \n",
    "print(len(weight_combines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature type weight optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Z_Helping_Functions import min_max_normalization, fast_argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimize_feature_type_weights(ref_measure_simi_train_dict: dict, k_sizes: list, weight_combines: list, \n",
    "                                  y_train: np.array, num_processors: int) -> list:\n",
    "    results = []\n",
    "    for k in tqdm(k_sizes):\n",
    "        result_at_k = evaluate_feature_type_weights_at_single_k(ref_measure_simi_train_dict, k, weight_combines, y_train, num_processors)\n",
    "        results.append(result_at_k)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Worker function to handle all weight combinations for a single k\n",
    "def evaluate_feature_type_weights_at_single_k(ref_measure_simi_train_dict: dict, k: int, \n",
    "                                              weight_combines: list, y_train: np.array, num_processors: int) -> list:\n",
    "    # Get the best feature type similarity measures for the current k\n",
    "    # Retrieve best similarity arrays\n",
    "    SCR_simi_train, LAB_simi_train = ref_measure_simi_train_dict[\"SCR\"], ref_measure_simi_train_dict[\"LAB\"]\n",
    "    \n",
    "    assert(SCR_simi_train.shape[0] == LAB_simi_train.shape[0])\n",
    "    assert(SCR_simi_train.shape[1] == LAB_simi_train.shape[1])\n",
    "\n",
    "    best_AUPRC = 0\n",
    "    best_weight_combo = None\n",
    "\n",
    "    # Iterate over all weight combinations\n",
    "    for (A, B) in weight_combines:\n",
    "        AUPRC, _ = evaluate_feature_type_weights(SCR_simi_train, LAB_simi_train, A, B, y_train, k, num_processors)\n",
    "        if AUPRC > best_AUPRC:\n",
    "            best_AUPRC = AUPRC\n",
    "            best_weight_combo = (A, B)\n",
    "\n",
    "    return [k, best_AUPRC, best_weight_combo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_feature_type_weights(SCR_simi_train, LAB_simi_train, A, B, y_train, k, num_processors):\n",
    "    # weighted sum of the simi mtxs and min-max normalization \n",
    "    combined_simi_train = A * SCR_simi_train + B * LAB_simi_train\n",
    "    combined_simi_train = min_max_normalization(combined_simi_train, axis = 1)\n",
    "    # get the ordered idx\n",
    "    combined_idx_train = fast_argsort(combined_simi_train, num_processors)\n",
    "    # organize the sorted idx into dict\n",
    "    idx_arr_train_combined, y_train_arr_combined = process_idx_arr_for_optimizing(combined_idx_train, y_train)\n",
    "    idx_y_wt_dict_train_combined = {\"idx\": idx_arr_train_combined, \"label\": y_train_arr_combined}\n",
    "    #evluate the KNN results\n",
    "    AUPRC, AUROC = KNN(idx_y_wt_dict_train_combined, k, y_train)\n",
    "    return AUPRC, AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_performance_nw_train = optimize_feature_type_weights(opt_measure_simi_nw_train_dict, k_sizes_train, \n",
    "                                                             weight_combines, y_train, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_performance_wt_train = optimize_feature_type_weights(opt_measure_simi_wt_train_dict, k_sizes_train, \n",
    "                                                             weight_combines, y_train, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_table[\"COMBINE NW\"] = [perf[2] for perf in weights_performance_nw_train]\n",
    "grid_search_table[\"COMBINE WT\"] = [perf[2] for perf in weights_performance_wt_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_table.to_csv(\"...\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_table = pd.read_csv(\"...\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Final Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Testing import test_final_personalized_model, get_best_weights, combine_best_weights_for_test, predict_by_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt_SCR_simi_nw_full = nw_fea_arrs_dict[\"SCR\"][best_distance_measures[\"SCR NW\"]][\"simi\"][\"full\"]\n",
    "opt_LAB_simi_nw_full = nw_fea_arrs_dict[\"LAB\"][best_distance_measures[\"LAB NW\"]][\"simi\"][\"full\"]\n",
    "opt_SCR_simi_wt_full = wt_fea_arrs_dict[\"SCR\"][best_distance_measures[\"SCR WT\"]][\"simi\"][\"full\"]\n",
    "opt_LAB_simi_wt_full = wt_fea_arrs_dict[\"LAB\"][best_distance_measures[\"LAB WT\"]][\"simi\"][\"full\"]\n",
    "\n",
    "opt_measure_simi_nw_full_dict = {\"SCR\": opt_SCR_simi_nw_full, \"LAB\": opt_LAB_simi_nw_full}\n",
    "opt_measure_simi_wt_full_dict = {\"SCR\": opt_SCR_simi_wt_full, \"LAB\": opt_LAB_simi_wt_full}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# these are the no nan features\n",
    "X_train = pd.concat([SCR_train, LAB_train], axis = 1)\n",
    "X_test = pd.concat([SCR_test, LAB_test], axis = 1)\n",
    "assert X_train.shape[1] == X_test.shape[1]\n",
    "# assert no nan values\n",
    "assert not X_train.isnull().values.any()\n",
    "assert not X_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 1: Optimized distance measure + optimized feature type weights + no overlap rates weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_model_performance_nw_KNN = test_final_personalized_model(X_train, X_test, k_sizes_test, grid_search_table, \n",
    "                                                           train_idx, test_idx, y_full, y_test, opt_measure_simi_nw_full_dict, \n",
    "                                                           num_processors, \"KNN\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_model_performance_nw_LR = test_final_personalized_model(X_train, X_test, k_sizes_test, grid_search_table, \n",
    "                                                           train_idx, test_idx, y_full, y_test, opt_measure_simi_nw_full_dict, \n",
    "                                                           num_processors, \"LR\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 2: Optimized distance measure + optimized feature type weights + overlap rates weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_model_performance_wt_KNN = test_final_personalized_model(X_train, X_test, k_sizes_test, grid_search_table, \n",
    "                                                           train_idx, test_idx, y_full, y_test, opt_measure_simi_wt_full_dict, \n",
    "                                                           num_processors, \"KNN\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_model_performance_wt_LR = test_final_personalized_model(X_train, X_test, k_sizes_test, grid_search_table, \n",
    "                                                           train_idx, test_idx, y_full, y_test, opt_measure_simi_wt_full_dict, \n",
    "                                                           num_processors, \"LR\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 3: Fixed Euclidean distance + fixed feature type weights, k = 20 + no overlap rates weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_k = 20\n",
    "base_fix_distance_performance_nw_KNN = {\"AUPRC\": [], \"AUROC\": []}\n",
    "base_fix_distance_performance_nw_LR = {\"AUPRC\": [], \"AUROC\": []}\n",
    "A_nw, B_nw = eval(get_best_weights(grid_search_table, base_k, False))\n",
    "base_fix_SCR_simi_nw_full = nw_fea_arrs_dict[\"SCR\"][\"DTW\"][\"simi\"][\"full\"]\n",
    "base_fix_LAB_simi_nw_full = nw_fea_arrs_dict[\"LAB\"][\"Euc\"][\"simi\"][\"full\"]\n",
    "fix_combined_weights_dict_nw = combine_best_weights_for_test(base_fix_SCR_simi_nw_full, base_fix_LAB_simi_nw_full, A_nw, B_nw, train_idx, test_idx, y_full, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in tqdm(k_sizes_test):\n",
    "    base_AUPRC_nw_KNN, base_AUROC_nw_KNN = KNN(fix_combined_weights_dict_nw, k, y_test)\n",
    "    base_fix_distance_performance_nw_KNN[\"AUPRC\"].append(base_AUPRC_nw_KNN)\n",
    "    base_fix_distance_performance_nw_KNN[\"AUROC\"].append(base_AUROC_nw_KNN)\n",
    "    base_AUPRC_nw_LR, base_AUROC_nw_LR = predict_by_LR(X_train, X_test, fix_combined_weights_dict_nw, k, y_test)\n",
    "    base_fix_distance_performance_nw_LR[\"AUPRC\"].append(base_AUPRC_nw_LR)\n",
    "    base_fix_distance_performance_nw_LR[\"AUROC\"].append(base_AUROC_nw_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 4: Optimized distance measure + fixed feature type weights, k = 20 + no overlap rates weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_opt_distance_performance_nw_KNN = {\"AUPRC\": [], \"AUROC\": []}\n",
    "base_opt_distance_performance_nw_LR = {\"AUPRC\": [], \"AUROC\": []}\n",
    "base_opt_SCR_simi_nw_full = nw_fea_arrs_dict[\"SCR\"][best_distance_measures[\"SCR NW\"]][\"simi\"][\"full\"]\n",
    "base_opt_LAB_simi_nw_full = nw_fea_arrs_dict[\"LAB\"][best_distance_measures[\"LAB NW\"]][\"simi\"][\"full\"]\n",
    "fix_combined_weights_dict_nw = combine_best_weights_for_test(base_opt_SCR_simi_nw_full, base_opt_LAB_simi_nw_full, A_nw, B_nw, train_idx, test_idx, y_full, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in tqdm(k_sizes_test):\n",
    "    base_AUPRC_nw_KNN, base_AUROC_nw_KNN = KNN(fix_combined_weights_dict_nw, k, y_test)\n",
    "    base_opt_distance_performance_nw_KNN[\"AUPRC\"].append(base_AUPRC_nw_KNN)\n",
    "    base_opt_distance_performance_nw_KNN[\"AUROC\"].append(base_AUROC_nw_KNN)\n",
    "    base_AUPRC_nw_LR, base_AUROC_nw_LR = predict_by_LR(X_train, X_test, fix_combined_weights_dict_nw, k, y_test)\n",
    "    base_opt_distance_performance_nw_LR[\"AUPRC\"].append(base_AUPRC_nw_LR)\n",
    "    base_opt_distance_performance_nw_LR[\"AUROC\"].append(base_AUROC_nw_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 5: Global Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = X_train.copy(deep = True)\n",
    "X_test_norm = X_test.copy(deep = True) \n",
    "X_train_norm.loc[:, :] = min_max_normalization(X_train_norm, axis = 0)\n",
    "X_test_norm.loc[:, :] = min_max_normalization(X_test_norm, axis = 0)\n",
    "X_full_norm = pd.concat([X_train_norm, X_test_norm], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_Euc_idx_full, _, _ = compute_similarity(X_full_norm, 'euclidean', train_len, num_processors)\n",
    "Euc_idx_arr_test_glob, Euc_y_test_arr_glob = process_idx_arr_for_test(train_idx, test_idx, X_Euc_idx_full, y_full)\n",
    "glob_Euc_idx_y_dict_test = {\"idx\": Euc_idx_arr_test_glob, \"label\": Euc_y_test_arr_glob}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_glob_Euc_performance_KNN = {\"AUPRC\": [], \"AUROC\": []}\n",
    "base_glob_Euc_performance_LR = {\"AUPRC\": [], \"AUROC\": []}\n",
    "for k in tqdm(k_sizes_test):\n",
    "    base_AUPRC_glob_KNN, base_AUROC_glob_KNN = KNN(glob_Euc_idx_y_dict_test, k, y_test)\n",
    "    base_glob_Euc_performance_KNN[\"AUPRC\"].append(base_AUPRC_glob_KNN)\n",
    "    base_glob_Euc_performance_KNN[\"AUROC\"].append(base_AUROC_glob_KNN)\n",
    "    base_AUPRC_glob_LR, base_AUROC_glob_LR = predict_by_LR(X_train, X_test, glob_Euc_idx_y_dict_test, k, y_test)\n",
    "    base_glob_Euc_performance_LR[\"AUPRC\"].append(base_AUPRC_glob_LR)\n",
    "    base_glob_Euc_performance_LR[\"AUROC\"].append(base_AUROC_glob_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 6: Global Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_Cos_idx_full, _, _ = compute_similarity(X_full_norm, 'cosine', train_len, num_processors)\n",
    "Cos_idx_arr_test_glob, Cos_y_test_arr_glob = process_idx_arr_for_test(train_idx, test_idx, X_Cos_idx_full, y_full)\n",
    "glob_Cos_idx_y_dict_test = {\"idx\": Cos_idx_arr_test_glob, \"label\": Cos_y_test_arr_glob}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_glob_Cos_performance_KNN = {\"AUPRC\": [], \"AUROC\": []}\n",
    "base_glob_Cos_performance_LR = {\"AUPRC\": [], \"AUROC\": []}\n",
    "for k in tqdm(k_sizes_test):\n",
    "    base_AUPRC_glob_KNN, base_AUROC_glob_KNN = KNN(glob_Cos_idx_y_dict_test, k, y_test)\n",
    "    base_glob_Cos_performance_KNN[\"AUPRC\"].append(base_AUPRC_glob_KNN)\n",
    "    base_glob_Cos_performance_KNN[\"AUROC\"].append(base_AUROC_glob_KNN)\n",
    "    base_AUPRC_glob_LR, base_AUROC_glob_LR = predict_by_LR(X_train, X_test, glob_Cos_idx_y_dict_test, k, y_test)\n",
    "    base_glob_Cos_performance_LR[\"AUPRC\"].append(base_AUPRC_glob_LR)\n",
    "    base_glob_Cos_performance_LR[\"AUROC\"].append(base_AUROC_glob_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Final Performance of Personalized Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "# List of dictionaries and their desired filenames\n",
    "dicts_to_save = {\n",
    "    \"base_glob_Euc_performance_KNN\": base_glob_Euc_performance_KNN,\n",
    "    \"base_glob_Cos_performance_KNN\": base_glob_Cos_performance_KNN,\n",
    "    \"base_fix_distance_performance_nw_KNN\": base_fix_distance_performance_nw_KNN,\n",
    "    \"base_opt_distance_performance_nw_KNN\": base_opt_distance_performance_nw_KNN,\n",
    "    \"final_model_performance_nw_KNN\": final_model_performance_nw_KNN,\n",
    "    \"final_model_performance_wt_KNN\": final_model_performance_wt_KNN,\n",
    "    \"base_glob_Euc_performance_LR\": base_glob_Euc_performance_LR,\n",
    "    \"base_glob_Cos_performance_LR\": base_glob_Cos_performance_LR,\n",
    "    \"base_fix_distance_performance_nw_LR\": base_fix_distance_performance_nw_LR,\n",
    "    \"base_opt_distance_performance_nw_LR\": base_opt_distance_performance_nw_LR,\n",
    "    \"final_model_performance_nw_LR\": final_model_performance_nw_LR,\n",
    "    \"final_model_performance_wt_LR\": final_model_performance_wt_LR,\n",
    "}\n",
    "\n",
    "# Directory to save the JSON files\n",
    "output_dir = \"./Results_dict/Main_results/\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save each dictionary as a JSON file\n",
    "for filename, data in dicts_to_save.items():\n",
    "    file_path = os.path.join(output_dir, f\"{filename}.json\")\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)  # Use indent=4 for pretty formatting\n",
    "    print(f\"Saved {filename} to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the JSON files\n",
    "input_dir = \"./Results_dict/Main_results/\"\n",
    "\n",
    "# Dictionary to store the loaded data\n",
    "loaded_dicts = {}\n",
    "\n",
    "# Load each JSON file and assign it to the corresponding variable name\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".json\"):  # Process only JSON files\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        variable_name = filename.replace(\".json\", \"\")  # Remove .json to create the variable name\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            globals()[variable_name] = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Plotting import plot_final_performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(13, 9.5)) \n",
    "\n",
    "plot_final_performance_metrics(axs[0, 0], k_sizes_test, \"AUPRC\", base_glob_Euc_performance_KNN, base_glob_Cos_performance_KNN, base_fix_distance_performance_nw_KNN, base_opt_distance_performance_nw_KNN, final_model_performance_nw_KNN, final_model_performance_wt_KNN, \"KNN\")\n",
    "plot_final_performance_metrics(axs[0, 1], k_sizes_test, \"AUROC\", base_glob_Euc_performance_KNN, base_glob_Cos_performance_KNN, base_fix_distance_performance_nw_KNN, base_opt_distance_performance_nw_KNN, final_model_performance_nw_KNN, final_model_performance_wt_KNN, \"KNN\")\n",
    "plot_final_performance_metrics(axs[1, 0], k_sizes_test, \"AUPRC\", base_glob_Euc_performance_LR, base_glob_Cos_performance_LR, base_fix_distance_performance_nw_LR, base_opt_distance_performance_nw_LR, final_model_performance_nw_LR, final_model_performance_wt_LR, \"Personalized LR\")\n",
    "plot_final_performance_metrics(axs[1, 1], k_sizes_test, \"AUROC\", base_glob_Euc_performance_LR, base_glob_Cos_performance_LR, base_fix_distance_performance_nw_LR, base_opt_distance_performance_nw_LR, final_model_performance_nw_LR, final_model_performance_wt_LR, \"Personalized LR\")\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"Final_model_performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Control Feature Type Weights on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Testing import combine_best_weights_for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_control_performance(k_sizes: list, weight_combines: list, train_idx: list, \n",
    "                                   test_idx: list, y_full: np.array, y_test: np.array, \n",
    "                                   opt_measure_simi_full_dict: dict, num_processors: int) -> dict:\n",
    "    results = dict()\n",
    "    \n",
    "    # get the corresponding simi mtx\n",
    "    SCR_simi_full, LAB_simi_full = opt_measure_simi_full_dict[\"SCR\"], opt_measure_simi_full_dict[\"LAB\"]\n",
    "    \n",
    "    for (A, B) in tqdm(weight_combines):\n",
    "        \n",
    "        results[str((A, B))] = {\"AUPRC\": [], \"AUROC\": []}\n",
    "        \n",
    "        combined_weights_dict = combine_best_weights_for_test(SCR_simi_full, LAB_simi_full, A, B, \n",
    "                                                              train_idx, test_idx, y_full, num_processors) \n",
    "        for k in k_sizes:\n",
    "            \n",
    "            AUPRC_full, AUROC_full = KNN(combined_weights_dict, k, y_test)\n",
    "            \n",
    "            results[str((A, B))][\"AUPRC\"].append(AUPRC_full)\n",
    "            results[str((A, B))][\"AUROC\"].append(AUROC_full)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights_performance_nw = get_weight_control_performance(k_sizes_test, weight_combines, \n",
    "                                                            train_idx, test_idx, y_full, y_test, \n",
    "                                                            opt_measure_simi_nw_full_dict, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights_performance_wt = get_weight_control_performance(k_sizes_test, weight_combines, \n",
    "                                                            train_idx, test_idx, y_full, y_test, \n",
    "                                                            opt_measure_simi_wt_full_dict, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_weights_performance(ax, k_sizes, all_weights_performance, \n",
    "                                 final_model_performance, title, metric):\n",
    "    \n",
    "    candidate_linecolor = ['lightblue', 'skyblue', 'deepskyblue', \n",
    "                           'dodgerblue', 'cornflowerblue', 'royalblue', \n",
    "                           'steelblue', 'mediumblue', 'darkblue', 'navy', \n",
    "                           'midnightblue', 'slateblue', 'powderblue', 'cadetblue']\n",
    "    \n",
    "    for i, weight_performance in enumerate(all_weights_performance.values()):\n",
    "        if i == 0:\n",
    "            label = \"Performance w/o FO\"\n",
    "        else:\n",
    "            label = \"\"\n",
    "            \n",
    "        ax.plot(k_sizes, weight_performance[metric], alpha = 0.25, marker='.', \n",
    "                markersize=10, color = candidate_linecolor[i], label = label)\n",
    "        \n",
    "    ax.plot(k_sizes, final_model_performance[metric], color = \"red\", alpha = 1,\n",
    "            label = \"Performance w/ FO\", marker='.', markersize=7)\n",
    "        \n",
    "    ax.set_title(title + \": \" + metric)\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.legend(loc = 'lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8))\n",
    "\n",
    "plot_all_weights_performance(axs[0, 0], k_sizes_test, all_weights_performance_nw, \n",
    "                                      final_model_performance_nw_KNN, \"KNN w/o OW\", \"AUPRC\")\n",
    "plot_all_weights_performance(axs[0, 1], k_sizes_test, all_weights_performance_nw, \n",
    "                                      final_model_performance_nw_KNN, \"KNN w/o OW\", \"AUROC\")\n",
    "plot_all_weights_performance(axs[1, 0], k_sizes_test, all_weights_performance_wt, \n",
    "                                      final_model_performance_wt_KNN, \"KNN w/ OW\", \"AUPRC\")\n",
    "plot_all_weights_performance(axs[1, 1], k_sizes_test, all_weights_performance_wt, \n",
    "                                      final_model_performance_wt_KNN, \"KNN w/ OW\", \"AUROC\")\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"All-feature-type-weights-performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Predicted Label Probabilities for Sub-group Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get predictions all on k = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_k_for_subgroup = [50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 2: Optimized distance measure + optimized feature type weights + overlap rates weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_proba_wt_KNN = test_final_personalized_model(X_train, X_test, base_k_for_subgroup, grid_search_table, \n",
    "                                                           train_idx, test_idx, y_full, y_test, opt_measure_simi_wt_full_dict, \n",
    "                                                           num_processors, \"KNN\", True, True)\n",
    "final_pred_proba_wt_LR = test_final_personalized_model(X_train, X_test, base_k_for_subgroup, grid_search_table, \n",
    "                                                           train_idx, test_idx, y_full, y_test, opt_measure_simi_wt_full_dict, \n",
    "                                                           num_processors, \"LR\", True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 4: Optimized distance measure + fixed feature type weights, k = 50 + no overlap rates weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pred_proba_nw_KNN = KNN(fix_combined_weights_dict_nw, base_k_for_subgroup[0], y_test, True)\n",
    "base_pred_proba_nw_LR = predict_by_LR(X_train, X_test, fix_combined_weights_dict_nw, base_k_for_subgroup[0], y_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 5: Global Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_Euc_pred_proba_glob_KNN = KNN(glob_Euc_idx_y_dict_test, base_k_for_subgroup[0], y_test, True)\n",
    "base_Euc_pred_proba_glob_LR = predict_by_LR(X_train, X_test, glob_Euc_idx_y_dict_test, base_k_for_subgroup[0], y_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 6: Global Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_Cos_pred_proba_glob_KNN = KNN(glob_Cos_idx_y_dict_test, base_k_for_subgroup[0], y_test, True)\n",
    "base_Cos_pred_proba_glob_LR = predict_by_LR(X_train, X_test, glob_Cos_idx_y_dict_test, base_k_for_subgroup[0], y_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the predictions for subgroup evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditions_KNN = pd.DataFrame(0.0, columns = [\"KNN (Euclidean)\", \"KNN (cosine)\", \"KNN (base)\", \"KNN (DO+FO+OW)\"], index = range(len(y_test)), dtype = float)\n",
    "preditions_LR = pd.DataFrame(0.0, columns = [\"Personalized LR (Euclidean)\", \"Personalized LR (cosine)\", \n",
    "                                             \"Personalized LR (base)\", \"Personalized LR (DO+FO+OW)\"], index = range(len(y_test)), dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preditions_KNN.loc[:, \"KNN (Euclidean)\"] = base_Euc_pred_proba_glob_KNN\n",
    "preditions_KNN.loc[:, \"KNN (cosine)\"] = base_Cos_pred_proba_glob_KNN\n",
    "preditions_KNN.loc[:, \"KNN (base)\"] = base_pred_proba_nw_KNN\n",
    "preditions_KNN.loc[:, \"KNN (DO+FO+OW)\"] = final_pred_proba_wt_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preditions_LR.loc[:, \"Personalized LR (Euclidean)\"] = base_Euc_pred_proba_glob_LR\n",
    "preditions_LR.loc[:, \"Personalized LR (cosine)\"] = base_Cos_pred_proba_glob_LR\n",
    "preditions_LR.loc[:, \"Personalized LR (base)\"] = base_pred_proba_nw_LR\n",
    "preditions_LR.loc[:, \"Personalized LR (DO+FO+OW)\"] = final_pred_proba_wt_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preditions_KNN.to_csv(\"...\", index = False)\n",
    "preditions_LR.to_csv(\"...\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_personalized_modeling",
   "language": "python",
   "name": "aki_personalized_modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
