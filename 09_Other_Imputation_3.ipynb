{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the variables\n",
    "with open('./utils/variables.json', 'r') as file:\n",
    "    variables = json.load(file)\n",
    "\n",
    "SCR_feature_space = variables['SCR_feature_space']\n",
    "LAB_feature_space = variables['LAB_feature_space']\n",
    "train_len = variables['train_len']\n",
    "test_len = variables['test_len']\n",
    "print(len(SCR_feature_space), len(LAB_feature_space))\n",
    "print(train_len, test_len)\n",
    "\n",
    "# get num_processors for parallel computing\n",
    "num_processors = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_folder = \"Imputation_3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read onset dadaset\n",
    "dataset = pd.read_csv(\".../dataset.csv\")\n",
    "# make sure the index is ordered\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "assert len(dataset) == train_len + test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test\n",
    "data_train = dataset.iloc[:train_len, :].copy(deep = True)\n",
    "data_test = dataset.iloc[train_len:, :].copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run DTW with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since DTW-AROW does not require missing data imputation, we run it first. Then we impute the data and run normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Distance_Computing import parallel_distance_matrix\n",
    "from utils.Z_Helping_Functions import translate_dist_mtx_to_simi, fast_argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCR_full = dataset.loc[:, SCR_feature_space].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_dist_full = parallel_distance_matrix(SCR_full, num_processors, get_DTW_distance)\n",
    "np.save('.../SCR_DTW_dist_imput2.npy', SCR_DTW_dist_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCR_DTW_dist_full = np.load('.../SCR_DTW_dist_imput2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfrom distance mtx to similarity score mtx by min-max normalization and substration from 1\n",
    "SCR_DTW_simi_full = translate_dist_mtx_to_simi(SCR_DTW_dist_full)\n",
    "# sort similarity score mtx into idx matrix by most similar rank highest. This is for the entire dataset, train + test\n",
    "SCR_DTW_idx_full = fast_argsort(SCR_DTW_simi_full, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the similarity matrix and idx rankings only for train set, this is for the one-vs-all training\n",
    "SCR_DTW_dist_train = SCR_DTW_dist_full[:len(data_train), :len(data_train)]\n",
    "SCR_DTW_simi_train = translate_dist_mtx_to_simi(SCR_DTW_dist_train)\n",
    "SCR_DTW_idx_train = fast_argsort(SCR_DTW_simi_train, num_processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Missing Values in LAB and LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB: KNN imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after imputation, we can safely split into train and test\n",
    "SCR_train = SCR_full.iloc[:train_len, :].copy(deep = True)\n",
    "SCR_test = SCR_full.iloc[train_len:, :].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_imputer = 5\n",
    "# Initialize KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=n_neighbors_imputer, weights=\"uniform\")\n",
    "\n",
    "# Fit the imputer on the train data (train only to avoid data leakage)\n",
    "knn_imputer.fit(SCR_train)\n",
    "\n",
    "# Impute missing values in train and test datasets\n",
    "SCR_train = pd.DataFrame(knn_imputer.transform(SCR_train), columns=SCR_train.columns)\n",
    "SCR_test = pd.DataFrame(knn_imputer.transform(SCR_test), columns=SCR_test.columns)\n",
    "SCR_full = pd.concat([SCR_train, SCR_test], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB: KNN imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is of note that the imputation is done on the lab train and lab test separately\n",
    "# this is to avoid data leakage\n",
    "LAB_train = data_train.loc[:, LAB_feature_space].copy(deep = True)\n",
    "LAB_test = data_test.loc[:, LAB_feature_space].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab normalization\n",
    "LAB_train = (LAB_train - LAB_train.min(skipna=True)) / (LAB_train.max(skipna=True) - LAB_train.min(skipna=True))\n",
    "LAB_test = (LAB_test - LAB_test.min(skipna=True)) / (LAB_test.max(skipna=True) - LAB_test.min(skipna=True))\n",
    "# Initialize KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=n_neighbors_imputer, weights=\"uniform\")\n",
    "# Fit the imputer on the train data (train only to avoid data leakage)\n",
    "knn_imputer.fit(LAB_train)\n",
    "# Impute missing values in train and test datasets\n",
    "LAB_train = pd.DataFrame(knn_imputer.transform(LAB_train), columns=LAB_train.columns)\n",
    "LAB_test = pd.DataFrame(knn_imputer.transform(LAB_test), columns=LAB_test.columns)\n",
    "# Concate train and test\n",
    "LAB_full = pd.concat([LAB_train, LAB_test], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Euclidean, Cosine and Manhattan Matrix of LAB and LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Distance_Computing import compute_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCR\n",
    "# Euclidean\n",
    "SCR_Euc_simi_full, SCR_Euc_idx_full, SCR_Euc_simi_train, SCR_Euc_idx_train = compute_similarity(SCR_full, 'euclidean', train_len, num_processors)\n",
    "# Cosine\n",
    "SCR_Cos_simi_full, SCR_Cos_idx_full, SCR_Cos_simi_train, SCR_Cos_idx_train = compute_similarity(SCR_full, 'cosine', train_len, num_processors)\n",
    "# Manhattan\n",
    "SCR_Manh_simi_full, SCR_Manh_idx_full, SCR_Manh_simi_train, SCR_Manh_idx_train = compute_similarity(SCR_full, 'manhattan', train_len, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAB\n",
    "# Euclidean\n",
    "LAB_Euc_simi_full, LAB_Euc_idx_full, LAB_Euc_simi_train, LAB_Euc_idx_train = compute_similarity(LAB_full, 'euclidean', train_len, num_processors)\n",
    "# Cosine\n",
    "LAB_Cos_simi_full, LAB_Cos_idx_full, LAB_Cos_simi_train, LAB_Cos_idx_train = compute_similarity(LAB_full, 'cosine', train_len, num_processors)\n",
    "# Manhattan\n",
    "LAB_Manh_simi_full, LAB_Manh_idx_full, LAB_Manh_simi_train, LAB_Manh_idx_train = compute_similarity(LAB_full, 'manhattan', train_len, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simi here is the un-ordered, normalized similarity score matrix, idx is the ordered paitent index matrix\n",
    "# nw stands for not weighted by data overlap rates matrix\n",
    "nw_fea_arrs_dict = {\"SCR\": {\"DTW\": {\"simi\": {\"full\": SCR_DTW_simi_full, \"train\": SCR_DTW_simi_train}, \"idx\": {\"full\": SCR_DTW_idx_full, \"train\": SCR_DTW_idx_train}}, \n",
    "                            \"Euc\": {\"simi\": {\"full\": SCR_Euc_simi_full, \"train\": SCR_Euc_simi_train}, \"idx\": {\"full\": SCR_Euc_idx_full, \"train\": SCR_Euc_idx_train}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": SCR_Cos_simi_full, \"train\": SCR_Cos_simi_train}, \"idx\": {\"full\": SCR_Cos_idx_full, \"train\": SCR_Cos_idx_train}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": SCR_Manh_simi_full, \"train\": SCR_Manh_simi_train}, \"idx\": {\"full\": SCR_Manh_idx_full, \"train\": SCR_Manh_idx_train}}}, \n",
    "                    \"LAB\": {\"Euc\": {\"simi\": {\"full\": LAB_Euc_simi_full, \"train\": LAB_Euc_simi_train}, \"idx\": {\"full\": LAB_Euc_idx_full, \"train\": LAB_Euc_idx_train}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": LAB_Cos_simi_full, \"train\": LAB_Cos_simi_train}, \"idx\": {\"full\": LAB_Cos_idx_full, \"train\": LAB_Cos_idx_train}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": LAB_Manh_simi_full, \"train\": LAB_Manh_simi_train}, \"idx\": {\"full\": LAB_Manh_idx_full, \"train\": LAB_Manh_idx_train}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overlap Rates Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pre-computed pairwise data overlap rates\n",
    "SCR_overlap_full = np.load('.../SCR_overlap.npy')\n",
    "LAB_overlap_full = np.load('.../lab_overlap.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consequently, we will only use the upper-left block of the overlap rate mtx for one-vs-all training\n",
    "SCR_overlap_train = SCR_overlap_full[:train_len, :train_len]\n",
    "LAB_overlap_train = LAB_overlap_full[:train_len, :train_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Distance_Computing import overlap_rates_weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on full data (for testing)\n",
    "# SCR\n",
    "SCR_DTW_simi_wt_full, SCR_DTW_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"DTW\"][\"simi\"][\"full\"], num_processors)\n",
    "SCR_Euc_simi_wt_full, SCR_Euc_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"Euc\"][\"simi\"][\"full\"], num_processors)\n",
    "SCR_Cos_simi_wt_full, SCR_Cos_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"Cos\"][\"simi\"][\"full\"], num_processors)\n",
    "SCR_Manh_simi_wt_full, SCR_Manh_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"Manh\"][\"simi\"][\"full\"], num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAB\n",
    "LAB_Euc_simi_wt_full, LAB_Euc_idx_wt_full = overlap_rates_weighting(LAB_overlap_full, nw_fea_arrs_dict[\"LAB\"][\"Euc\"][\"simi\"][\"full\"], num_processors)\n",
    "LAB_Cos_simi_wt_full, LAB_Cos_idx_wt_full = overlap_rates_weighting(LAB_overlap_full, nw_fea_arrs_dict[\"LAB\"][\"Cos\"][\"simi\"][\"full\"], num_processors)\n",
    "LAB_Manh_simi_wt_full, LAB_Manh_idx_wt_full = overlap_rates_weighting(LAB_overlap_full, nw_fea_arrs_dict[\"LAB\"][\"Manh\"][\"simi\"][\"full\"], num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on training data (for one-vs-all training)\n",
    "# SCR\n",
    "SCR_DTW_simi_wt_train, SCR_DTW_idx_wt_train = overlap_rates_weighting(SCR_overlap_train, nw_fea_arrs_dict[\"SCR\"][\"DTW\"][\"simi\"][\"train\"], num_processors)\n",
    "SCR_Euc_simi_wt_train, SCR_Euc_idx_wt_train = overlap_rates_weighting(SCR_overlap_train, nw_fea_arrs_dict[\"SCR\"][\"Euc\"][\"simi\"][\"train\"], num_processors)\n",
    "SCR_Cos_simi_wt_train, SCR_Cos_idx_wt_train = overlap_rates_weighting(SCR_overlap_train, nw_fea_arrs_dict[\"SCR\"][\"Cos\"][\"simi\"][\"train\"], num_processors)\n",
    "SCR_Manh_simi_wt_train, SCR_Manh_idx_wt_train = overlap_rates_weighting(SCR_overlap_train, nw_fea_arrs_dict[\"SCR\"][\"Manh\"][\"simi\"][\"train\"], num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAB\n",
    "LAB_Euc_simi_wt_train, LAB_Euc_idx_wt_train = overlap_rates_weighting(LAB_overlap_train, nw_fea_arrs_dict[\"LAB\"][\"Euc\"][\"simi\"][\"train\"], num_processors)\n",
    "LAB_Cos_simi_wt_train, LAB_Cos_idx_wt_train = overlap_rates_weighting(LAB_overlap_train, nw_fea_arrs_dict[\"LAB\"][\"Cos\"][\"simi\"][\"train\"], num_processors)\n",
    "LAB_Manh_simi_wt_train, LAB_Manh_idx_wt_train = overlap_rates_weighting(LAB_overlap_train, nw_fea_arrs_dict[\"LAB\"][\"Manh\"][\"simi\"][\"train\"], num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simi here is the un-ordered, normalized similarity score matrix, idx is the ordered paitent index matrix\n",
    "# nw stands for not weighted by data overlap rates matrix\n",
    "wt_fea_arrs_dict = {\"SCR\": {\"DTW\": {\"simi\": {\"full\": SCR_DTW_simi_wt_full, \"train\": SCR_DTW_simi_wt_train}, \"idx\": {\"full\": SCR_DTW_idx_wt_full, \"train\": SCR_DTW_idx_wt_train}}, \n",
    "                            \"Euc\": {\"simi\": {\"full\": SCR_Euc_simi_wt_full, \"train\": SCR_Euc_simi_wt_train}, \"idx\": {\"full\": SCR_Euc_idx_wt_full, \"train\": SCR_Euc_idx_wt_train}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": SCR_Cos_simi_wt_full, \"train\": SCR_Cos_simi_wt_train}, \"idx\": {\"full\": SCR_Cos_idx_wt_full, \"train\": SCR_Cos_idx_wt_train}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": SCR_Manh_simi_wt_full, \"train\": SCR_Manh_simi_wt_train}, \"idx\": {\"full\": SCR_Manh_idx_wt_full, \"train\": SCR_Manh_idx_wt_train}}}, \n",
    "                    \"LAB\": {\"Euc\": {\"simi\": {\"full\": LAB_Euc_simi_wt_full, \"train\": LAB_Euc_simi_wt_train}, \"idx\": {\"full\": LAB_Euc_idx_wt_full, \"train\": LAB_Euc_idx_wt_train}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": LAB_Cos_simi_wt_full, \"train\": LAB_Cos_simi_wt_train}, \"idx\": {\"full\": LAB_Cos_idx_wt_full, \"train\": LAB_Cos_idx_wt_train}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": LAB_Manh_simi_wt_full, \"train\": LAB_Manh_simi_wt_train}, \"idx\": {\"full\": LAB_Manh_idx_wt_full, \"train\": LAB_Manh_idx_wt_train}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Distance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighborhood sizes for optimizing best distance measures\n",
    "k_sizes_train = [i for i in range(10, 201, 5)]\n",
    "print(len(k_sizes_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate simi_dict for one-vs-all val\n",
    "def process_idx_arr_for_optimizing(idx_arr: np.array, y_train: np.array) -> tuple[np.array, np.array]:\n",
    "    idx_arr_clean = remove_row_idx(idx_arr)\n",
    "    y_train_arr = sort_by_idx_arr(idx_arr_clean, y_train)\n",
    "    return idx_arr_clean, y_train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_row_idx(idx_arr: np.array) -> np.array:    \n",
    "    # Create a list to hold the new rows\n",
    "    idx_arr_clean = []\n",
    "    \n",
    "    # Iterate through each row in the matrix\n",
    "    for row_index in range(idx_arr.shape[0]):\n",
    "        # Get the current row\n",
    "        row = idx_arr[row_index]\n",
    "        # Create a new row excluding the element equal to the row index\n",
    "        new_row = row[row != row_index]\n",
    "        # Append the new row to the new_matrix list\n",
    "        idx_arr_clean.append(new_row)\n",
    "    \n",
    "    # Convert the list of rows back to a NumPy array\n",
    "    idx_arr_clean = np.array(idx_arr_clean)\n",
    "    \n",
    "    return idx_arr_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_idx_arr(idx_arr: np.array, y_train: np.array) -> np.array:\n",
    "    y_train_arr = np.tile(y_train, (idx_arr.shape[0], 1))\n",
    "    # Use advanced indexing to select the elements from matrix_b\n",
    "    row_indices = np.arange(idx_arr.shape[0])[:, None]  # Create an array of row indices\n",
    "    y_train_arr = y_train_arr[row_indices, idx_arr]  # Use the row indices and matrix_a for advanced indexing\n",
    "    \n",
    "    return y_train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = list(data_train.index)\n",
    "test_idx = list(data_test.index)\n",
    "y_train = np.array(data_train[\"AKI_LABEL\"])\n",
    "y_test = np.array(data_test[\"AKI_LABEL\"])\n",
    "y_full = np.array(dataset[\"AKI_LABEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the similarity score array into array that can be used for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCR\n",
    "SCR_idx_y_nw_dict_train = {}\n",
    "SCR_idx_y_wt_dict_train = {}\n",
    "\n",
    "for dist_measure, arrs in tqdm(nw_fea_arrs_dict[\"SCR\"].items()):\n",
    "    idx_arr_train_clean, y_train_arr = process_idx_arr_for_optimizing(arrs[\"idx\"][\"train\"], y_train)\n",
    "    SCR_idx_y_nw_dict_train[dist_measure] = {\"idx\": idx_arr_train_clean, \"label\": y_train_arr}\n",
    "for dist_measure, arrs in tqdm(wt_fea_arrs_dict[\"SCR\"].items()):\n",
    "    idx_arr_train_clean, y_train_arr = process_idx_arr_for_optimizing(arrs[\"idx\"][\"train\"], y_train)\n",
    "    SCR_idx_y_wt_dict_train[dist_measure] = {\"idx\": idx_arr_train_clean, \"label\": y_train_arr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab\n",
    "LAB_idx_y_nw_dict_train = {}\n",
    "LAB_idx_y_wt_dict_train = {}\n",
    "\n",
    "for dist_measure, arrs in tqdm(nw_fea_arrs_dict[\"LAB\"].items()):\n",
    "    idx_arr_train_clean, y_train_arr = process_idx_arr_for_optimizing(arrs[\"idx\"][\"train\"], y_train)\n",
    "    LAB_idx_y_nw_dict_train[dist_measure] = {\"idx\": idx_arr_train_clean, \"label\": y_train_arr}\n",
    "for dist_measure, arrs in tqdm(wt_fea_arrs_dict[\"LAB\"].items()):\n",
    "    idx_arr_train_clean, y_train_arr = process_idx_arr_for_optimizing(arrs[\"idx\"][\"train\"], y_train)\n",
    "    LAB_idx_y_wt_dict_train[dist_measure] = {\"idx\": idx_arr_train_clean, \"label\": y_train_arr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize distance measure at each k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Testing import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distance_measures(clean_arrs_dict: dict, y_test: np.array, k_sizes: int) -> dict:\n",
    "    \n",
    "    best_method_each_k = {\"name\": [], \"AUPRC\": []}\n",
    "    \n",
    "    for k in tqdm(k_sizes):\n",
    "        \n",
    "        best_method_name = ''\n",
    "        best_method_AUPRC = 0\n",
    "        \n",
    "        for name, arr_dict in clean_arrs_dict.items():\n",
    "            AUPRC, _ = KNN(arr_dict, k, y_test)\n",
    "            \n",
    "            # if better AUPRC, update\n",
    "            if AUPRC > best_method_AUPRC:\n",
    "                best_method_name = name\n",
    "                best_method_AUPRC = AUPRC\n",
    "                \n",
    "        best_method_each_k[\"name\"].append(best_method_name)\n",
    "        best_method_each_k[\"AUPRC\"].append(best_method_AUPRC)\n",
    "    \n",
    "    return best_method_each_k    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table to track all performance\n",
    "# NW is not overlap rates weighting\n",
    "# WT is overlap rates weighting\n",
    "grid_search_table = pd.DataFrame('', index = k_sizes_train, columns = [\"SCR NW\", \"LAB NW\", \"SCR WT\", \"LAB WT\"])\n",
    "grid_search_table.index.name = \"k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCR_nw = compare_distance_measures(SCR_idx_y_nw_dict_train, y_train, k_sizes_train)\n",
    "SCR_wt = compare_distance_measures(SCR_idx_y_wt_dict_train, y_train, k_sizes_train)\n",
    "LAB_nw = compare_distance_measures(LAB_idx_y_nw_dict_train, y_train, k_sizes_train)\n",
    "LAB_wt = compare_distance_measures(LAB_idx_y_wt_dict_train, y_train, k_sizes_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_table.loc[:, \"SCR NW\"] = SCR_nw[\"name\"]\n",
    "grid_search_table.loc[:, \"SCR WT\"] = SCR_wt[\"name\"]\n",
    "grid_search_table.loc[:, \"LAB NW\"] = LAB_nw[\"name\"]\n",
    "grid_search_table.loc[:, \"LAB WT\"] = LAB_wt[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To facilitate computing, we do not use the idea of unique distance measure for each k\n",
    "# instead one metric for one condition. We use the metric that previal in the column\n",
    "best_distance_measures = dict()\n",
    "for column in grid_search_table.columns:\n",
    "    mode_value = grid_search_table[column].mode()[0]\n",
    "    best_distance_measures[column] = mode_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Best Distance Measures on Test Set Using KNN/LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the similarity score array into array that can be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Testing import get_best_method, process_idx_arr_for_test, evluate_on_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCR\n",
    "SCR_idx_y_nw_dict_test = {}\n",
    "SCR_idx_y_wt_dict_test = {}\n",
    "\n",
    "for dist_measure, arrs in tqdm(nw_fea_arrs_dict[\"SCR\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    SCR_idx_y_nw_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}\n",
    "for dist_measure, arrs in tqdm(wt_fea_arrs_dict[\"SCR\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    SCR_idx_y_wt_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAB\n",
    "LAB_idx_y_nw_dict_test = {}\n",
    "LAB_idx_y_wt_dict_test = {}\n",
    "\n",
    "for dist_measure, arrs in tqdm(nw_fea_arrs_dict[\"LAB\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    LAB_idx_y_nw_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}\n",
    "for dist_measure, arrs in tqdm(wt_fea_arrs_dict[\"LAB\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    LAB_idx_y_wt_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance by using KNN/LR as the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we reduce the number of k to be tested\n",
    "k_sizes_test = [i for i in range(10, 201, 10)]\n",
    "print(len(k_sizes_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_control_KNN, _ = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"DTW\", \"Euc\", \n",
    "                                             y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                             LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_control_LR, _ = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"DTW\", \"Euc\", \n",
    "                                             y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                             LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Euc_control_KNN, LAB_Euc_control_KNN = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Euc\", \"Euc\", y_test, k_sizes_test, \n",
    "                                                               SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                               LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Euc_control_LR, LAB_Euc_control_LR = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Euc\", \"Euc\", \n",
    "                                                             y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                             LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Cos_control_KNN, LAB_Cos_control_KNN = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Cos\", \"Cos\", \n",
    "                                                               y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                               LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Cos_control_LR, LAB_Cos_control_LR = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Cos\", \"Cos\", \n",
    "                                                               y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                               LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Manh_control_KNN, LAB_Manh_control_KNN = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Manh\", \"Manh\", \n",
    "                                                                 y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                                 LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Manh_control_LR, LAB_Manh_control_LR = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Manh\", \"Manh\", \n",
    "                                                                y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                                LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NW_WT_performace_results = {\n",
    "    \"SCR_DTW_control_KNN\": SCR_DTW_control_KNN,\n",
    "    \"SCR_DTW_control_LR\": SCR_DTW_control_LR,\n",
    "    \"SCR_Euc_control_KNN\": SCR_Euc_control_KNN,\n",
    "    \"LAB_Euc_control_KNN\": LAB_Euc_control_KNN,\n",
    "    \"SCR_Euc_control_LR\": SCR_Euc_control_LR,\n",
    "    \"LAB_Euc_control_LR\": LAB_Euc_control_LR,\n",
    "    \"SCR_Cos_control_KNN\": SCR_Cos_control_KNN,\n",
    "    \"LAB_Cos_control_KNN\": LAB_Cos_control_KNN,\n",
    "    \"SCR_Cos_control_LR\": SCR_Cos_control_LR,\n",
    "    \"LAB_Cos_control_LR\": LAB_Cos_control_LR,\n",
    "    \"SCR_Manh_control_KNN\": SCR_Manh_control_KNN,\n",
    "    \"LAB_Manh_control_KNN\": LAB_Manh_control_KNN,\n",
    "    \"SCR_Manh_control_LR\": SCR_Manh_control_LR,\n",
    "    \"LAB_Manh_control_LR\": LAB_Manh_control_LR,\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"./Results_dict/Imputation_3/NW_WT_performace_results.json\", \"w\") as json_file:\n",
    "    json.dump(NW_WT_performace_results, json_file, indent=4)  # Use indent for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot and Prove: Data Overlap Rates Weighting can Improve Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Plotting import plot_metric_along_k, add_subplot_index, save_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./Results_dict/Imputation_3/NW_WT_performace_results.json\", \"r\") as json_file:\n",
    "    NW_WT_performace_results = json.load(json_file)\n",
    "SCR_DTW_control_KNN = NW_WT_performace_results[\"SCR_DTW_control_KNN\"]  \n",
    "SCR_DTW_control_LR = NW_WT_performace_results[\"SCR_DTW_control_LR\"]  \n",
    "SCR_Euc_control_KNN = NW_WT_performace_results[\"SCR_Euc_control_KNN\"]  \n",
    "LAB_Euc_control_KNN = NW_WT_performace_results[\"LAB_Euc_control_KNN\"]  \n",
    "SCR_Euc_control_LR = NW_WT_performace_results[\"SCR_Euc_control_LR\"]  \n",
    "LAB_Euc_control_LR = NW_WT_performace_results[\"LAB_Euc_control_LR\"]  \n",
    "SCR_Cos_control_KNN = NW_WT_performace_results[\"SCR_Cos_control_KNN\"]  \n",
    "LAB_Cos_control_KNN = NW_WT_performace_results[\"LAB_Cos_control_KNN\"]  \n",
    "SCR_Cos_control_LR = NW_WT_performace_results[\"SCR_Cos_control_LR\"]  \n",
    "LAB_Cos_control_LR = NW_WT_performace_results[\"LAB_Cos_control_LR\"]\n",
    "SCR_Manh_control_KNN = NW_WT_performace_results[\"SCR_Manh_control_KNN\"]\n",
    "LAB_Manh_control_KNN = NW_WT_performace_results[\"LAB_Manh_control_KNN\"]\n",
    "SCR_Manh_control_LR = NW_WT_performace_results[\"SCR_Manh_control_LR\"]\n",
    "LAB_Manh_control_LR = NW_WT_performace_results[\"LAB_Manh_control_LR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_KNN[\"NW\"][metric], SCR_DTW_control_KNN[\"WT\"][metric], \"SCr-KNN, DTW-AROW: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_KNN[\"NW\"][metric], SCR_Euc_control_KNN[\"WT\"][metric], \"SCr-KNN, Euclidean: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_KNN[\"NW\"][metric], SCR_Cos_control_KNN[\"WT\"][metric], \"SCr-KNN, Cosine: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_KNN[\"NW\"][metric], SCR_Manh_control_KNN[\"WT\"][metric], \"SCr-KNN, Manhattan: %s\"%(metric), metric, 'KNN')\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-KNN-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_KNN[\"NW\"][metric], SCR_DTW_control_KNN[\"WT\"][metric], \"SCr-KNN, DTW-AROW: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_KNN[\"NW\"][metric], SCR_Euc_control_KNN[\"WT\"][metric], \"SCr-KNN, Euclidean: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_KNN[\"NW\"][metric], SCR_Cos_control_KNN[\"WT\"][metric], \"SCr-KNN, Cosine: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_KNN[\"NW\"][metric], SCR_Manh_control_KNN[\"WT\"][metric], \"SCr-KNN, Manhattan: %s\"%(metric), metric, 'KNN')\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-KNN-AUROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_LR[\"NW\"][metric], SCR_DTW_control_LR[\"WT\"][metric], \"SCr-LR, DTW-AROW: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_LR[\"NW\"][metric], SCR_Euc_control_LR[\"WT\"][metric], \"SCr-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_LR[\"NW\"][metric], SCR_Cos_control_LR[\"WT\"][metric], \"SCr-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_LR[\"NW\"][metric], SCR_Manh_control_LR[\"WT\"][metric], \"SCr-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-LR-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_LR[\"NW\"][metric], SCR_DTW_control_LR[\"WT\"][metric], \"SCr-LR, DTW-AROW: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_LR[\"NW\"][metric], SCR_Euc_control_LR[\"WT\"][metric], \"SCr-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_LR[\"NW\"][metric], SCR_Cos_control_LR[\"WT\"][metric], \"SCr-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_LR[\"NW\"][metric], SCR_Manh_control_LR[\"WT\"][metric], \"SCr-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-LR-AUROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_KNN[\"NW\"][metric], LAB_Euc_control_KNN[\"WT\"][metric], \"Lab-KNN, Euclidean: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_KNN[\"NW\"][metric], LAB_Cos_control_KNN[\"WT\"][metric], \"Lab-KNN, Cosine: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_KNN[\"NW\"][metric], LAB_Manh_control_KNN[\"WT\"][metric], \"Lab-KNN, Manhattan: %s\"%(metric), metric, \"KNN\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-KNN-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_KNN[\"NW\"][metric], LAB_Euc_control_KNN[\"WT\"][metric], \"Lab-KNN, Euclidean: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_KNN[\"NW\"][metric], LAB_Cos_control_KNN[\"WT\"][metric], \"Lab-KNN, Cosine: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_KNN[\"NW\"][metric], LAB_Manh_control_KNN[\"WT\"][metric], \"Lab-KNN, Manhattan: %s\"%(metric), metric, \"KNN\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-KNN-AUROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_LR[\"NW\"][metric], LAB_Euc_control_LR[\"WT\"][metric], \"Lab-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_LR[\"NW\"][metric], LAB_Cos_control_LR[\"WT\"][metric], \"Lab-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_LR[\"NW\"][metric], LAB_Manh_control_LR[\"WT\"][metric], \"Lab-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-LR-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_LR[\"NW\"][metric], LAB_Euc_control_LR[\"WT\"][metric], \"Lab-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_LR[\"NW\"][metric], LAB_Cos_control_LR[\"WT\"][metric], \"Lab-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_LR[\"NW\"][metric], LAB_Manh_control_LR[\"WT\"][metric], \"Lab-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-LR-AUROC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_personalized_modeling",
   "language": "python",
   "name": "aki_personalized_modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
