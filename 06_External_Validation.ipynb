{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import json\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import os\n",
    "# pandas show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the variables\n",
    "with open('./utils/variables.json', 'r') as file:\n",
    "    variables = json.load(file)\n",
    "\n",
    "SCR_feature_space = variables['SCR_feature_space']\n",
    "LAB_feature_space = variables['LAB_feature_space']\n",
    "train_len = variables['train_len']\n",
    "test_len = variables['test_len']\n",
    "print(len(SCR_feature_space), len(LAB_feature_space))\n",
    "print(train_len, test_len)\n",
    "\n",
    "# get num_processors for parallel computing\n",
    "num_processors = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figure_folder = \"External_validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process UPITT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read in Onsets data and only use KUMC data\n",
    "All_onsets = pd.read_csv('.../NEW_ONSETS.csv')\n",
    "ext_ONSET = All_onsets.loc[All_onsets.CENTER_NAME == \"UPITT\"].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read in lab\n",
    "raw_path = '/blue/yonghui.wu/hoyinchan/Data/data2022raw/'\n",
    "data_path = raw_path + \"UPITT\" + '/raw/'\n",
    "ext_LAB = pd.read_csv(data_path + 'AKI_LAB.csv', delimiter = ',', usecols = ['PATID', 'LAB_LOINC', 'SPECIMEN_DATE', 'RESULT_NUM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in SCr trajectories\n",
    "SCR_use_cols = ['ONSETS_ENCOUNTERID','PATID','ENCOUNTERID','SPECIMEN_DATE','RESULT_NUM', 'DAYS_SINCE_ADMIT']\n",
    "ext_SCR = pd.read_csv(data_path + \"AKI_LAB_SCR.csv\", delimiter = ',', usecols=SCR_use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#format datatype for merge\n",
    "#exclude those baseline SCr > 3.5, which indicate poor renal functions\n",
    "ext_ONSET = ext_ONSET.loc[ext_ONSET.SERUM_CREAT_BASE < 3.5, :].copy(deep = True)\n",
    "\n",
    "ext_ONSET.loc[:, [\"PATID\", \"ONSETS_ENCOUNTERID\"]] = ext_ONSET[[\"PATID\", \"ONSETS_ENCOUNTERID\"]].astype(str)\n",
    "\n",
    "time_cols = [\"ADMIT_DATE\", \"DISCHARGE_DATE\", \"AKI1_ONSET\", \"AKI2_ONSET\", \"AKI3_ONSET\"]\n",
    "for time_col in time_cols:\n",
    "    ext_ONSET[time_col] = pd.to_datetime(ext_ONSET[time_col], format = \"mixed\")\n",
    "    \n",
    "# binary predictiton task\n",
    "ext_ONSET.loc[:, \"EARLIEST_ONSET_DATE\"] = np.min(ext_ONSET[[\"AKI1_ONSET\", \"AKI2_ONSET\", \"AKI3_ONSET\"]], axis = 1)\n",
    "ext_ONSET.loc[:, \"AKI_LABEL\"] = ext_ONSET[\"EARLIEST_ONSET_DATE\"].notna().astype(int)\n",
    "\n",
    "ext_ONSET.drop([\"CENTER_NAME\", \"SERUM_CREAT_BASE\", \"NONAKI_SINCE_ADMIT\", \"AKI1_ONSET\",\n",
    "           \"AKI2_ONSET\", \"AKI3_ONSET\"], axis = 1, inplace = True)\n",
    "\n",
    "#process data type \n",
    "ext_SCR[\"PATID\"] = ext_SCR[\"PATID\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ext_ONSET_SCR = ext_ONSET.merge(ext_SCR[[\"PATID\", \"SPECIMEN_DATE\", \"RESULT_NUM\"]], on = \"PATID\", how = \"left\")\n",
    "#after merging, process date time\n",
    "ext_ONSET_SCR[\"SPECIMEN_DATE\"] = pd.to_datetime(ext_ONSET_SCR[\"SPECIMEN_DATE\"], format = \"mixed\")\n",
    "#filter out those beyond this hospitalization (we also need history prior to this hospitalization)\n",
    "ext_ONSET_SCR = ext_ONSET_SCR.loc[ext_ONSET_SCR.SPECIMEN_DATE <= ext_ONSET_SCR.DISCHARGE_DATE, :]\n",
    "ext_ONSET_SCR = ext_ONSET_SCR.sort_values(by=['PATID', 'ADMIT_DATE', 'SPECIMEN_DATE'])\n",
    "# get average SCr on the same day\n",
    "ext_ONSET_SCR_avg = ext_ONSET_SCR.groupby(['PATID', 'ONSETS_ENCOUNTERID', 'SPECIMEN_DATE'])['RESULT_NUM'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# append the info back\n",
    "ext_ONSET_SCR_app = ext_ONSET_SCR.loc[:, [\"PATID\", \"ONSETS_ENCOUNTERID\", \"ADMIT_DATE\", \"DISCHARGE_DATE\", \"EARLIEST_ONSET_DATE\", \"AKI_LABEL\"]]\n",
    "ext_ONSET_SCR_app.drop_duplicates(inplace = True)\n",
    "ext_ONSET_SCR_avg = ext_ONSET_SCR_app.merge(ext_ONSET_SCR_avg, on = [\"PATID\", \"ONSETS_ENCOUNTERID\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the prediction point for non-AKI patient\n",
    "ext_non_AKI_pat = ext_ONSET_SCR_avg.loc[ext_ONSET_SCR_avg.AKI_LABEL == 0, [\"PATID\", \"ONSETS_ENCOUNTERID\", \"SPECIMEN_DATE\"]]\n",
    "ext_non_AKI_pat.drop_duplicates(subset = [\"PATID\", \"ONSETS_ENCOUNTERID\"], keep = \"last\", inplace = True)\n",
    "ext_non_AKI_pat.rename(columns = {\"SPECIMEN_DATE\": \"PREDICTION_POINT\"}, inplace = True)\n",
    "ext_ONSET_SCR_avg = ext_ONSET_SCR_avg.merge(ext_non_AKI_pat, on = [\"PATID\", \"ONSETS_ENCOUNTERID\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ext_ONSET_SCR_avg.loc[ext_ONSET_SCR_avg.AKI_LABEL == 1, \"PREDICTION_POINT\"] = ext_ONSET_SCR_avg.loc[ext_ONSET_SCR_avg.AKI_LABEL == 1, \"EARLIEST_ONSET_DATE\"]\n",
    "#check that we have predicition point for each encounter\n",
    "assert(ext_ONSET_SCR_avg.PREDICTION_POINT.isna().mean() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the time frame we need for SCr is the -8 to -2 days prior to prediction point\n",
    "ext_ONSET_SCR_avg = ext_ONSET_SCR_avg[((ext_ONSET_SCR_avg.SPECIMEN_DATE <= (ext_ONSET_SCR_avg.PREDICTION_POINT) - pd.Timedelta(days=2))) & \\\n",
    "                             (ext_ONSET_SCR_avg.SPECIMEN_DATE >= ext_ONSET_SCR_avg.PREDICTION_POINT - pd.Timedelta(days=8))]\n",
    "#drop patients with less than 2 SCr measurements during the 7-day window\n",
    "# group them and calcualte number of measurements\n",
    "measure_num = ext_ONSET_SCR_avg.groupby('ONSETS_ENCOUNTERID').size()\n",
    "encounterID_to_drop = measure_num[measure_num < 2].index\n",
    "ext_ONSET_SCR_avg = ext_ONSET_SCR_avg.loc[~ext_ONSET_SCR_avg.ONSETS_ENCOUNTERID.isin(encounterID_to_drop), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pivot all the SCr values, that is create features -8 ~ -2 and entries are RESULT_NUM\n",
    "ext_ONSET_SCR_avg[\"DAYS_BEFORE_PREDICTION_POINT\"] = (ext_ONSET_SCR_avg[\"SPECIMEN_DATE\"] - ext_ONSET_SCR_avg[\"PREDICTION_POINT\"]).dt.days\n",
    "\n",
    "#prepare a skleleton to merge on\n",
    "unique_encounterids = list(ext_ONSET_SCR_avg['ONSETS_ENCOUNTERID'].unique())\n",
    "time_window = np.arange(-8, -1)  # from -8 to -2\n",
    "skeleton = pd.MultiIndex.from_product([unique_encounterids, time_window], \n",
    "                                      names=['ONSETS_ENCOUNTERID', 'DAYS_BEFORE_PREDICTION_POINT']).to_frame(index=False)\n",
    "#merge on\n",
    "skeleton = pd.merge(skeleton, ext_ONSET_SCR_avg, on=['ONSETS_ENCOUNTERID', 'DAYS_BEFORE_PREDICTION_POINT'], how='left')\n",
    "\n",
    "#pivot\n",
    "ONSET_SCR_formatted = skeleton.pivot(index='ONSETS_ENCOUNTERID', \n",
    "                                          columns='DAYS_BEFORE_PREDICTION_POINT', \n",
    "                                          values='RESULT_NUM').reset_index()\n",
    "\n",
    "# get other info back\n",
    "ONSET_SCR_app2 = ext_ONSET_SCR_avg.loc[:, [\"PATID\", \"ONSETS_ENCOUNTERID\", \"ADMIT_DATE\", \"DISCHARGE_DATE\", \n",
    "                                       \"PREDICTION_POINT\", \"AKI_LABEL\"]]\n",
    "ONSET_SCR_app2.drop_duplicates(inplace = True)\n",
    "ext_ONSET_SCR_formatted = ONSET_SCR_formatted.merge(ONSET_SCR_app2, on = \"ONSETS_ENCOUNTERID\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only keep the earliest encounter of each patient\n",
    "ext_ONSET_SCR_formatted = ext_ONSET_SCR_formatted.sort_values(by=['PATID', 'ADMIT_DATE'])\n",
    "ext_ONSET_SCR_formatted = ext_ONSET_SCR_formatted.drop_duplicates(subset='PATID', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ext_LAB[\"PATID\"] = ext_LAB[\"PATID\"].astype(str)\n",
    "# merge the lab \n",
    "ext_ONSET_SCR_LAB = ext_ONSET_SCR_formatted.merge(ext_LAB, on = \"PATID\", how = \"left\")\n",
    "ext_ONSET_SCR_LAB[\"SPECIMEN_DATE\"] = pd.to_datetime(ext_ONSET_SCR_LAB[\"SPECIMEN_DATE\"], format = \"mixed\")\n",
    "ext_ONSET_SCR_LAB = ext_ONSET_SCR_LAB[(ext_ONSET_SCR_LAB.SPECIMEN_DATE <= (ext_ONSET_SCR_LAB.PREDICTION_POINT - pd.Timedelta(days=2))) & \\\n",
    "                              (ext_ONSET_SCR_LAB.SPECIMEN_DATE >= ext_ONSET_SCR_LAB.ADMIT_DATE - pd.Timedelta(days=8))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we only keep the lastest result of a certain lab within the time window\n",
    "ext_ONSET_SCR_LAB_temp = ext_ONSET_SCR_LAB.sort_values(by=['PATID', 'ONSETS_ENCOUNTERID', 'LAB_LOINC', 'SPECIMEN_DATE'])\n",
    "ext_ONSET_SCR_LAB_temp = ext_ONSET_SCR_LAB_temp.groupby(['PATID', 'ONSETS_ENCOUNTERID', 'LAB_LOINC']).last().reset_index()\n",
    "#turn lab into feature columns\n",
    "ext_LAB_info = ext_ONSET_SCR_LAB_temp.pivot(index='ONSETS_ENCOUNTERID', columns='LAB_LOINC', values='RESULT_NUM')\n",
    "ext_LAB_info = ext_LAB_info.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# align feature space with the internal dataset\n",
    "ext_LAB_info = ext_LAB_info[[\"ONSETS_ENCOUNTERID\"] + LAB_feature_space]\n",
    "#merge them back to the original dataframe\n",
    "ext_ONSET_SCR_LAB = ext_ONSET_SCR_formatted.merge(ext_LAB_info, on = 'ONSETS_ENCOUNTERID', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample the External Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r start_date\n",
    "%store -r split_date\n",
    "%store -r end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter patients that from the same time range and sample number\n",
    "ext_test = ext_ONSET_SCR_LAB[(ext_ONSET_SCR_LAB.ADMIT_DATE >= split_date) & (ext_ONSET_SCR_LAB.ADMIT_DATE < end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ext_test_sampled, _ = train_test_split(\n",
    "    ext_test, \n",
    "    test_size=(len(ext_test) - test_len) / len(ext_test), \n",
    "    random_state=88, \n",
    "    stratify=ext_test['AKI_LABEL']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ext_test_sampled.to_csv('.../ext_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ext_test_sampled = pd.read_csv('.../ext_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# re-index the external dataset such that the index start from train_len\n",
    "ext_test_sampled.index = range(train_len, train_len + len(ext_test_sampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Internal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "int_dataset = pd.read_csv(\".../dataset.csv\")\n",
    "assert(len(int_dataset) == (train_len + test_len))\n",
    "int_train = int_dataset.iloc[:train_len, :].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# align the feature space with the internal dataset\n",
    "int_train.columns = int_train.columns.map(str)\n",
    "ext_test_sampled.columns = ext_test_sampled.columns.map(str)\n",
    "ext_test_sampled = ext_test_sampled.loc[:, SCR_feature_space + LAB_feature_space + ['AKI_LABEL']]\n",
    "# concatenate the two datasets\n",
    "dataset_full = pd.concat([int_train, ext_test_sampled], axis = 0)\n",
    "dataset_full.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Data Overlap Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_full = dataset_full.loc[:, SCR_feature_space]\n",
    "LAB_full = dataset_full.loc[:, LAB_feature_space]\n",
    "SCR_full_bin = SCR_full.notna().astype(int)\n",
    "LAB_full_bin = LAB_full.notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Data_Overlap_Rates_Computing import parallel_overlap_matrix_comp, check_matrix_sanity, calculate_overlap_rate_SCR, calculate_overlap_rate_LAB\n",
    "%store -r normal_distribution_SCR\n",
    "%store -r lab_overlap_weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_overlap = parallel_overlap_matrix_comp(SCR_full_bin, num_processors, calculate_overlap_rate_SCR, normal_distribution_SCR)\n",
    "check_matrix_sanity(SCR_overlap)\n",
    "print(np.median(SCR_overlap))\n",
    "print(np.mean(SCR_overlap))\n",
    "np.save('.../SCR_overlap_external.npy', SCR_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAB_overlap = parallel_overlap_matrix_comp(LAB_full_bin, num_processors, calculate_overlap_rate_LAB, lab_overlap_weighting)\n",
    "check_matrix_sanity(LAB_overlap)\n",
    "print(np.median(LAB_overlap))\n",
    "print(np.mean(LAB_overlap))\n",
    "np.save('.../lab_overlap_external.npy', LAB_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Distance_Computing import parallel_distance_matrix, get_DTW_distance\n",
    "from utils.Z_Helping_Functions import translate_dist_mtx_to_simi, fast_argsort, min_max_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_dist_full = parallel_distance_matrix(SCR_full, num_processors, get_DTW_distance)\n",
    "np.save('.../SCR_DTW_dist_external.npy', SCR_DTW_dist_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_dist_full = np.load('.../SCR_DTW_dist_external.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transfrom distance mtx to similarity score mtx by min-max normalization and substration from 1\n",
    "SCR_DTW_simi_full = translate_dist_mtx_to_simi(SCR_DTW_dist_full)\n",
    "# sort similarity score mtx into idx matrix by most similar rank highest. This is for the entire dataset, train + test\n",
    "SCR_DTW_idx_full = fast_argsort(SCR_DTW_simi_full, num_processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute Missing Values for SCR and LAB Respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCR, since it just row wise we do not need to split into train and test\n",
    "SCR_full = SCR_full.interpolate(method='linear', axis = 1)\n",
    "SCR_full = SCR_full.bfill(axis=1)\n",
    "SCR_full = SCR_full.ffill(axis=1)\n",
    "# after imputation, we can safely split into train and test\n",
    "SCR_train = SCR_full.iloc[:train_len, :].copy(deep = True)\n",
    "SCR_test = SCR_full.iloc[train_len:, :].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# it is of note that the imputation is done on the lab train and lab test separately\n",
    "# this is to avoid data leakage\n",
    "LAB_train = int_train.loc[:, LAB_feature_space].copy(deep = True)\n",
    "LAB_test = ext_test_sampled.loc[:, LAB_feature_space].copy(deep = True)\n",
    "# lab normalization\n",
    "LAB_train = (LAB_train - LAB_train.min(skipna=True)) / (LAB_train.max(skipna=True) - LAB_train.min(skipna=True))\n",
    "LAB_test = (LAB_test - LAB_test.min(skipna=True)) / (LAB_test.max(skipna=True) - LAB_test.min(skipna=True))\n",
    "# impute lab missing values\n",
    "imputer = IterativeImputer(missing_values=np.nan, max_iter=1000, random_state=42)\n",
    "imputer.fit(LAB_train)\n",
    "LAB_train_temp = imputer.transform(LAB_train)\n",
    "LAB_test_temp = imputer.transform(LAB_test)\n",
    "LAB_train.loc[:, :] = LAB_train_temp\n",
    "LAB_test.loc[:, :] = LAB_test_temp\n",
    "# Concate train and test\n",
    "LAB_full = pd.concat([LAB_train, LAB_test], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean, Cosine and Manhattan Matrix of SCR and LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Distance_Computing import compute_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCR\n",
    "# Euclidean\n",
    "SCR_Euc_simi_full, SCR_Euc_idx_full, _, _ = compute_similarity(SCR_full, 'euclidean', train_len, num_processors)\n",
    "# Cosine\n",
    "SCR_Cos_simi_full, SCR_Cos_idx_full, _, _ = compute_similarity(SCR_full, 'cosine', train_len, num_processors)\n",
    "# Manhattan\n",
    "SCR_Manh_simi_full, SCR_Manh_idx_full, _, _ = compute_similarity(SCR_full, 'manhattan', train_len, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LAB\n",
    "# Euclidean\n",
    "LAB_Euc_simi_full, LAB_Euc_idx_full, _, _ = compute_similarity(LAB_full, 'euclidean', train_len, num_processors)\n",
    "# Cosine\n",
    "LAB_Cos_simi_full, LAB_Cos_idx_full, _, _ = compute_similarity(LAB_full, 'cosine', train_len, num_processors)\n",
    "# Manhattan\n",
    "LAB_Manh_simi_full, LAB_Manh_idx_full, _, _ = compute_similarity(LAB_full, 'manhattan', train_len, num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simi here is the un-ordered, normalized similarity score matrix, idx is the ordered paitent index matrix\n",
    "# nw stands for not weighted by data overlap rates matrix\n",
    "nw_fea_arrs_dict = {\"SCR\": {\"DTW\": {\"simi\": {\"full\": SCR_DTW_simi_full}, \"idx\": {\"full\": SCR_DTW_idx_full}}, \n",
    "                            \"Euc\": {\"simi\": {\"full\": SCR_Euc_simi_full}, \"idx\": {\"full\": SCR_Euc_idx_full}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": SCR_Cos_simi_full}, \"idx\": {\"full\": SCR_Cos_idx_full}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": SCR_Manh_simi_full}, \"idx\": {\"full\": SCR_Manh_idx_full}}}, \n",
    "                    \"LAB\": {\"Euc\": {\"simi\": {\"full\": LAB_Euc_simi_full}, \"idx\": {\"full\": LAB_Euc_idx_full}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": LAB_Cos_simi_full}, \"idx\": {\"full\": LAB_Cos_idx_full}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": LAB_Manh_simi_full}, \"idx\": {\"full\": LAB_Manh_idx_full}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overlap Rates Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Distance_Computing import overlap_rates_weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read pre-computed pairwise data overlap rates\n",
    "SCR_overlap_full = np.load('.../SCR_overlap_external.npy')\n",
    "LAB_overlap_full = np.load('.../lab_overlap_external.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# on full data (for testing)\n",
    "# SCR\n",
    "SCR_DTW_simi_wt_full, SCR_DTW_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"DTW\"][\"simi\"][\"full\"], num_processors)\n",
    "SCR_Euc_simi_wt_full, SCR_Euc_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"Euc\"][\"simi\"][\"full\"], num_processors)\n",
    "SCR_Cos_simi_wt_full, SCR_Cos_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"Cos\"][\"simi\"][\"full\"], num_processors)\n",
    "SCR_Manh_simi_wt_full, SCR_Manh_idx_wt_full = overlap_rates_weighting(SCR_overlap_full, nw_fea_arrs_dict[\"SCR\"][\"Manh\"][\"simi\"][\"full\"], num_processors)\n",
    "\n",
    "# LAB\n",
    "LAB_Euc_simi_wt_full, LAB_Euc_idx_wt_full = overlap_rates_weighting(LAB_overlap_full, nw_fea_arrs_dict[\"LAB\"][\"Euc\"][\"simi\"][\"full\"], num_processors)\n",
    "LAB_Cos_simi_wt_full, LAB_Cos_idx_wt_full = overlap_rates_weighting(LAB_overlap_full, nw_fea_arrs_dict[\"LAB\"][\"Cos\"][\"simi\"][\"full\"], num_processors)\n",
    "LAB_Manh_simi_wt_full, LAB_Manh_idx_wt_full = overlap_rates_weighting(LAB_overlap_full, nw_fea_arrs_dict[\"LAB\"][\"Manh\"][\"simi\"][\"full\"], num_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simi here is the un-ordered, normalized similarity score matrix, idx is the ordered paitent index matrix\n",
    "# nw stands for not weighted by data overlap rates matrix\n",
    "wt_fea_arrs_dict = {\"SCR\": {\"DTW\": {\"simi\": {\"full\": SCR_DTW_simi_wt_full}, \"idx\": {\"full\": SCR_DTW_idx_wt_full}}, \n",
    "                            \"Euc\": {\"simi\": {\"full\": SCR_Euc_simi_wt_full}, \"idx\": {\"full\": SCR_Euc_idx_wt_full}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": SCR_Cos_simi_wt_full}, \"idx\": {\"full\": SCR_Cos_idx_wt_full}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": SCR_Manh_simi_wt_full}, \"idx\": {\"full\": SCR_Manh_idx_wt_full}}}, \n",
    "                    \"LAB\": {\"Euc\": {\"simi\": {\"full\": LAB_Euc_simi_wt_full}, \"idx\": {\"full\": LAB_Euc_idx_wt_full}}, \n",
    "                            \"Cos\": {\"simi\": {\"full\": LAB_Cos_simi_wt_full}, \"idx\": {\"full\": LAB_Cos_idx_wt_full}}, \n",
    "                            \"Manh\":{\"simi\": {\"full\": LAB_Manh_simi_wt_full}, \"idx\": {\"full\": LAB_Manh_idx_wt_full}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Best Distance Measures on Test Set Using KNN/LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_idx = dataset_full.iloc[:train_len, :].index\n",
    "test_idx = dataset_full.iloc[train_len:, :].index\n",
    "y_test = np.array(ext_test_sampled['AKI_LABEL'])\n",
    "y_full = np.array(dataset_full['AKI_LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Testing import process_idx_arr_for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCR\n",
    "SCR_idx_y_nw_dict_test = {}\n",
    "SCR_idx_y_wt_dict_test = {}\n",
    "for dist_measure, arrs in tqdm(nw_fea_arrs_dict[\"SCR\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    SCR_idx_y_nw_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}\n",
    "for dist_measure, arrs in tqdm(wt_fea_arrs_dict[\"SCR\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    SCR_idx_y_wt_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LAB\n",
    "LAB_idx_y_nw_dict_test = {}\n",
    "LAB_idx_y_wt_dict_test = {}\n",
    "for dist_measure, arrs in tqdm(nw_fea_arrs_dict[\"LAB\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    LAB_idx_y_nw_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}\n",
    "for dist_measure, arrs in tqdm(wt_fea_arrs_dict[\"LAB\"].items()):\n",
    "    idx_arr_test_clean, y_test_arr = process_idx_arr_for_test(train_idx, test_idx, arrs[\"idx\"][\"full\"], y_full)\n",
    "    LAB_idx_y_wt_dict_test[dist_measure] = {\"idx\": idx_arr_test_clean, \"label\": y_test_arr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we reduce the number of k to be tested\n",
    "k_sizes_test = [i for i in range(10, 201, 10)]\n",
    "print(len(k_sizes_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Testing import evluate_on_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_control_KNN, _ = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"DTW\", \"Euc\", \n",
    "                                             y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                             LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_DTW_control_LR, _ = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"DTW\", \"Euc\", \n",
    "                                             y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                             LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Euc_control_KNN, LAB_Euc_control_KNN = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Euc\", \"Euc\", y_test, k_sizes_test, \n",
    "                                                               SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                               LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Euc_control_LR, LAB_Euc_control_LR = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Euc\", \"Euc\", \n",
    "                                                             y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                             LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Cos_control_KNN, LAB_Cos_control_KNN = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Cos\", \"Cos\", \n",
    "                                                               y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                               LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Cos_control_LR, LAB_Cos_control_LR = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Cos\", \"Cos\", \n",
    "                                                               y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                               LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Manh_control_KNN, LAB_Manh_control_KNN = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Manh\", \"Manh\", \n",
    "                                                                 y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                                 LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_Manh_control_LR, LAB_Manh_control_LR = evluate_on_test_set(SCR_train, SCR_test, LAB_train, LAB_test, \"Manh\", \"Manh\", \n",
    "                                                                y_test, k_sizes_test, SCR_idx_y_nw_dict_test, SCR_idx_y_wt_dict_test, \n",
    "                                                                LAB_idx_y_nw_dict_test, LAB_idx_y_wt_dict_test, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NW_WT_performace_results = {\n",
    "    \"SCR_DTW_control_KNN\": SCR_DTW_control_KNN,\n",
    "    \"SCR_DTW_control_LR\": SCR_DTW_control_LR,\n",
    "    \"SCR_Euc_control_KNN\": SCR_Euc_control_KNN,\n",
    "    \"LAB_Euc_control_KNN\": LAB_Euc_control_KNN,\n",
    "    \"SCR_Euc_control_LR\": SCR_Euc_control_LR,\n",
    "    \"LAB_Euc_control_LR\": LAB_Euc_control_LR,\n",
    "    \"SCR_Cos_control_KNN\": SCR_Cos_control_KNN,\n",
    "    \"LAB_Cos_control_KNN\": LAB_Cos_control_KNN,\n",
    "    \"SCR_Cos_control_LR\": SCR_Cos_control_LR,\n",
    "    \"LAB_Cos_control_LR\": LAB_Cos_control_LR,\n",
    "    \"SCR_Manh_control_KNN\": SCR_Manh_control_KNN,\n",
    "    \"LAB_Manh_control_KNN\": LAB_Manh_control_KNN,\n",
    "    \"SCR_Manh_control_LR\": SCR_Manh_control_LR,\n",
    "    \"LAB_Manh_control_LR\": LAB_Manh_control_LR,\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"./Results_dict/External_validation/NW_WT_performace_results.json\", \"w\") as json_file:\n",
    "    json.dump(NW_WT_performace_results, json_file, indent=4)  # Use indent for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot and Prove: Data Overlap Rates Weighting can Improve Performance in External Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Plotting import plot_metric_along_k, add_subplot_index, save_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./Results_dict/External_validation/NW_WT_performace_results.json\", \"r\") as json_file:\n",
    "    NW_WT_performace_results = json.load(json_file)\n",
    "SCR_DTW_control_KNN = NW_WT_performace_results[\"SCR_DTW_control_KNN\"]  \n",
    "SCR_DTW_control_LR = NW_WT_performace_results[\"SCR_DTW_control_LR\"]  \n",
    "SCR_Euc_control_KNN = NW_WT_performace_results[\"SCR_Euc_control_KNN\"]  \n",
    "LAB_Euc_control_KNN = NW_WT_performace_results[\"LAB_Euc_control_KNN\"]  \n",
    "SCR_Euc_control_LR = NW_WT_performace_results[\"SCR_Euc_control_LR\"]  \n",
    "LAB_Euc_control_LR = NW_WT_performace_results[\"LAB_Euc_control_LR\"]  \n",
    "SCR_Cos_control_KNN = NW_WT_performace_results[\"SCR_Cos_control_KNN\"]  \n",
    "LAB_Cos_control_KNN = NW_WT_performace_results[\"LAB_Cos_control_KNN\"]  \n",
    "SCR_Cos_control_LR = NW_WT_performace_results[\"SCR_Cos_control_LR\"]  \n",
    "LAB_Cos_control_LR = NW_WT_performace_results[\"LAB_Cos_control_LR\"]\n",
    "SCR_Manh_control_KNN = NW_WT_performace_results[\"SCR_Manh_control_KNN\"]\n",
    "LAB_Manh_control_KNN = NW_WT_performace_results[\"LAB_Manh_control_KNN\"]\n",
    "SCR_Manh_control_LR = NW_WT_performace_results[\"SCR_Manh_control_LR\"]\n",
    "LAB_Manh_control_LR = NW_WT_performace_results[\"LAB_Manh_control_LR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_KNN[\"NW\"][metric], SCR_DTW_control_KNN[\"WT\"][metric], \"SCr-KNN, DTW-AROW: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_KNN[\"NW\"][metric], SCR_Euc_control_KNN[\"WT\"][metric], \"SCr-KNN, Euclidean: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_KNN[\"NW\"][metric], SCR_Cos_control_KNN[\"WT\"][metric], \"SCr-KNN, Cosine: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_KNN[\"NW\"][metric], SCR_Manh_control_KNN[\"WT\"][metric], \"SCr-KNN, Manhattan: %s\"%(metric), metric, 'KNN')\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-KNN-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_KNN[\"NW\"][metric], SCR_DTW_control_KNN[\"WT\"][metric], \"SCr-KNN, DTW-AROW: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_KNN[\"NW\"][metric], SCR_Euc_control_KNN[\"WT\"][metric], \"SCr-KNN, Euclidean: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_KNN[\"NW\"][metric], SCR_Cos_control_KNN[\"WT\"][metric], \"SCr-KNN, Cosine: %s\"%(metric), metric, 'KNN')\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_KNN[\"NW\"][metric], SCR_Manh_control_KNN[\"WT\"][metric], \"SCr-KNN, Manhattan: %s\"%(metric), metric, 'KNN')\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-KNN-AUROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_LR[\"NW\"][metric], SCR_DTW_control_LR[\"WT\"][metric], \"SCr-LR, DTW-AROW: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_LR[\"NW\"][metric], SCR_Euc_control_LR[\"WT\"][metric], \"SCr-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_LR[\"NW\"][metric], SCR_Cos_control_LR[\"WT\"][metric], \"SCr-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_LR[\"NW\"][metric], SCR_Manh_control_LR[\"WT\"][metric], \"SCr-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-LR-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(11, 8)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0,0], k_sizes_test, SCR_DTW_control_LR[\"NW\"][metric], SCR_DTW_control_LR[\"WT\"][metric], \"SCr-LR, DTW-AROW: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[0,1], k_sizes_test, SCR_Euc_control_LR[\"NW\"][metric], SCR_Euc_control_LR[\"WT\"][metric], \"SCr-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,0], k_sizes_test, SCR_Cos_control_LR[\"NW\"][metric], SCR_Cos_control_LR[\"WT\"][metric], \"SCr-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1,1], k_sizes_test, SCR_Manh_control_LR[\"NW\"][metric], SCR_Manh_control_LR[\"WT\"][metric], \"SCr-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"SCR-LR-AUROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_KNN[\"NW\"][metric], LAB_Euc_control_KNN[\"WT\"][metric], \"Lab-KNN, Euclidean: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_KNN[\"NW\"][metric], LAB_Cos_control_KNN[\"WT\"][metric], \"Lab-KNN, Cosine: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_KNN[\"NW\"][metric], LAB_Manh_control_KNN[\"WT\"][metric], \"Lab-KNN, Manhattan: %s\"%(metric), metric, \"KNN\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-KNN-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_KNN[\"NW\"][metric], LAB_Euc_control_KNN[\"WT\"][metric], \"Lab-KNN, Euclidean: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_KNN[\"NW\"][metric], LAB_Cos_control_KNN[\"WT\"][metric], \"Lab-KNN, Cosine: %s\"%(metric), metric, \"KNN\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_KNN[\"NW\"][metric], LAB_Manh_control_KNN[\"WT\"][metric], \"Lab-KNN, Manhattan: %s\"%(metric), metric, \"KNN\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-KNN-AUROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUPRC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_LR[\"NW\"][metric], LAB_Euc_control_LR[\"WT\"][metric], \"Lab-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_LR[\"NW\"][metric], LAB_Cos_control_LR[\"WT\"][metric], \"Lab-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_LR[\"NW\"][metric], LAB_Manh_control_LR[\"WT\"][metric], \"Lab-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-LR-AUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12.5, 3.5)) \n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "plot_metric_along_k(axs[0], k_sizes_test, LAB_Euc_control_LR[\"NW\"][metric], LAB_Euc_control_LR[\"WT\"][metric], \"Lab-LR, Euclidean: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[1], k_sizes_test, LAB_Cos_control_LR[\"NW\"][metric], LAB_Cos_control_LR[\"WT\"][metric], \"Lab-LR, Cosine: %s\"%(metric), metric, \"LR\")\n",
    "plot_metric_along_k(axs[2], k_sizes_test, LAB_Manh_control_LR[\"NW\"][metric], LAB_Manh_control_LR[\"WT\"][metric], \"Lab-LR, Manhattan: %s\"%(metric), metric, \"LR\")\n",
    "add_subplot_index(axs, 1, 3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"LAB-LR-AUROC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Final Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Testing import test_final_personalized_model, get_best_weights, combine_best_weights_for_test, KNN, predict_by_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_table = pd.read_csv(\".../grid_search_table_imput2_LR.csv\", index_col = 0)\n",
    "best_distance_measures = dict()\n",
    "for column in grid_search_table.columns:\n",
    "    mode_value = grid_search_table[column].mode()[0]\n",
    "    best_distance_measures[column] = mode_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt_SCR_simi_nw_full = nw_fea_arrs_dict[\"SCR\"][best_distance_measures[\"SCR NW\"]][\"simi\"][\"full\"]\n",
    "opt_LAB_simi_nw_full = nw_fea_arrs_dict[\"LAB\"][best_distance_measures[\"LAB NW\"]][\"simi\"][\"full\"]\n",
    "opt_SCR_simi_wt_full = wt_fea_arrs_dict[\"SCR\"][best_distance_measures[\"SCR WT\"]][\"simi\"][\"full\"]\n",
    "opt_LAB_simi_wt_full = wt_fea_arrs_dict[\"LAB\"][best_distance_measures[\"LAB WT\"]][\"simi\"][\"full\"]\n",
    "\n",
    "opt_measure_simi_nw_full_dict = {\"SCR\": opt_SCR_simi_nw_full, \"LAB\": opt_LAB_simi_nw_full}\n",
    "opt_measure_simi_wt_full_dict = {\"SCR\": opt_SCR_simi_wt_full, \"LAB\": opt_LAB_simi_wt_full}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# these are the no nan features\n",
    "X_train = pd.concat([SCR_train, LAB_train], axis = 1)\n",
    "X_test = pd.concat([SCR_test, LAB_test], axis = 1)\n",
    "assert X_train.shape[1] == X_test.shape[1]\n",
    "# assert no nan values\n",
    "assert not X_train.isnull().values.any(), \"The DataFrame contains NaN values!\"\n",
    "assert not X_test.isnull().values.any(), \"The DataFrame contains NaN values!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 1: Optimized distance measure + optimized feature type weights + no overlap rates weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_model_performance_nw_KNN = test_final_personalized_model(X_train, X_test, k_sizes_test, grid_search_table, \n",
    "                                                           train_idx, test_idx, y_full, y_test, opt_measure_simi_nw_full_dict, \n",
    "                                                           num_processors, \"KNN\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_model_performance_nw_LR = test_final_personalized_model(X_train, X_test, k_sizes_test, grid_search_table, \n",
    "                                                           train_idx, test_idx, y_full, y_test, opt_measure_simi_nw_full_dict, \n",
    "                                                           num_processors, \"LR\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 2: Optimized distance measure + optimized feature type weights + overlap rates weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_model_performance_wt_KNN = test_final_personalized_model(X_train, X_test, k_sizes_test, grid_search_table, \n",
    "                                                           train_idx, test_idx, y_full, y_test, opt_measure_simi_wt_full_dict, \n",
    "                                                           num_processors, \"KNN\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_model_performance_wt_LR = test_final_personalized_model(X_train, X_test, k_sizes_test, grid_search_table, \n",
    "                                                           train_idx, test_idx, y_full, y_test, opt_measure_simi_wt_full_dict, \n",
    "                                                           num_processors, \"LR\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 3: Fixed Euclidean distance + fixed feature type weights, k = 20 + no overlap rates weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_k = 20\n",
    "base_fix_distance_performance_nw_KNN = {\"AUPRC\": [], \"AUROC\": []}\n",
    "base_fix_distance_performance_nw_LR = {\"AUPRC\": [], \"AUROC\": []}\n",
    "A_nw, B_nw = eval(get_best_weights(grid_search_table, base_k, False))\n",
    "base_fix_SCR_simi_nw_full = nw_fea_arrs_dict[\"SCR\"][\"DTW\"][\"simi\"][\"full\"]\n",
    "base_fix_LAB_simi_nw_full = nw_fea_arrs_dict[\"LAB\"][\"Euc\"][\"simi\"][\"full\"]\n",
    "fix_combined_weights_dict_nw = combine_best_weights_for_test(base_fix_SCR_simi_nw_full, base_fix_LAB_simi_nw_full, A_nw, B_nw, train_idx, test_idx, y_full, num_processors)\n",
    "\n",
    "for k in tqdm(k_sizes_test):\n",
    "    base_AUPRC_nw_KNN, base_AUROC_nw_KNN = KNN(fix_combined_weights_dict_nw, k, y_test)\n",
    "    base_fix_distance_performance_nw_KNN[\"AUPRC\"].append(base_AUPRC_nw_KNN)\n",
    "    base_fix_distance_performance_nw_KNN[\"AUROC\"].append(base_AUROC_nw_KNN)\n",
    "    base_AUPRC_nw_LR, base_AUROC_nw_LR = predict_by_LR(X_train, X_test, fix_combined_weights_dict_nw, k, y_test)\n",
    "    base_fix_distance_performance_nw_LR[\"AUPRC\"].append(base_AUPRC_nw_LR)\n",
    "    base_fix_distance_performance_nw_LR[\"AUROC\"].append(base_AUROC_nw_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 4: Optimized distance measure + fixed feature type weights, k = 20 + no overlap rates weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_opt_distance_performance_nw_KNN = {\"AUPRC\": [], \"AUROC\": []}\n",
    "base_opt_distance_performance_nw_LR = {\"AUPRC\": [], \"AUROC\": []}\n",
    "base_opt_SCR_simi_nw_full = nw_fea_arrs_dict[\"SCR\"][best_distance_measures[\"SCR NW\"]][\"simi\"][\"full\"]\n",
    "base_opt_LAB_simi_nw_full = nw_fea_arrs_dict[\"LAB\"][best_distance_measures[\"LAB NW\"]][\"simi\"][\"full\"]\n",
    "fix_combined_weights_dict_nw = combine_best_weights_for_test(base_opt_SCR_simi_nw_full, base_opt_LAB_simi_nw_full, A_nw, B_nw, train_idx, test_idx, y_full, num_processors)\n",
    "\n",
    "for k in tqdm(k_sizes_test):\n",
    "    base_AUPRC_nw_KNN, base_AUROC_nw_KNN = KNN(fix_combined_weights_dict_nw, k, y_test)\n",
    "    base_opt_distance_performance_nw_KNN[\"AUPRC\"].append(base_AUPRC_nw_KNN)\n",
    "    base_opt_distance_performance_nw_KNN[\"AUROC\"].append(base_AUROC_nw_KNN)\n",
    "    base_AUPRC_nw_LR, base_AUROC_nw_LR = predict_by_LR(X_train, X_test, fix_combined_weights_dict_nw, k, y_test)\n",
    "    base_opt_distance_performance_nw_LR[\"AUPRC\"].append(base_AUPRC_nw_LR)\n",
    "    base_opt_distance_performance_nw_LR[\"AUROC\"].append(base_AUROC_nw_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 5: Global Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_norm = X_train.copy(deep = True)\n",
    "X_test_norm = X_test.copy(deep = True) \n",
    "X_train_norm.loc[:, :] = min_max_normalization(X_train_norm, axis = 0)\n",
    "X_test_norm.loc[:, :] = min_max_normalization(X_test_norm, axis = 0)\n",
    "X_full_norm = pd.concat([X_train_norm, X_test_norm], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, X_Euc_idx_full, _, _ = compute_similarity(X_full_norm, 'euclidean', train_len, num_processors)\n",
    "Euc_idx_arr_test_glob, Euc_y_test_arr_glob = process_idx_arr_for_test(train_idx, test_idx, X_Euc_idx_full, y_full)\n",
    "glob_Euc_idx_y_dict_test = {\"idx\": Euc_idx_arr_test_glob, \"label\": Euc_y_test_arr_glob}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_glob_Euc_performance_KNN = {\"AUPRC\": [], \"AUROC\": []}\n",
    "base_glob_Euc_performance_LR = {\"AUPRC\": [], \"AUROC\": []}\n",
    "for k in tqdm(k_sizes_test):\n",
    "    base_AUPRC_glob_KNN, base_AUROC_glob_KNN = KNN(glob_Euc_idx_y_dict_test, k, y_test)\n",
    "    base_glob_Euc_performance_KNN[\"AUPRC\"].append(base_AUPRC_glob_KNN)\n",
    "    base_glob_Euc_performance_KNN[\"AUROC\"].append(base_AUROC_glob_KNN)\n",
    "    base_AUPRC_glob_LR, base_AUROC_glob_LR = predict_by_LR(X_train, X_test, glob_Euc_idx_y_dict_test, k, y_test)\n",
    "    base_glob_Euc_performance_LR[\"AUPRC\"].append(base_AUPRC_glob_LR)\n",
    "    base_glob_Euc_performance_LR[\"AUROC\"].append(base_AUROC_glob_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance 6: Global Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, X_Cos_idx_full, _, _ = compute_similarity(X_full_norm, 'cosine', train_len, num_processors)\n",
    "Cos_idx_arr_test_glob, Cos_y_test_arr_glob = process_idx_arr_for_test(train_idx, test_idx, X_Cos_idx_full, y_full)\n",
    "glob_Cos_idx_y_dict_test = {\"idx\": Cos_idx_arr_test_glob, \"label\": Cos_y_test_arr_glob}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_glob_Cos_performance_KNN = {\"AUPRC\": [], \"AUROC\": []}\n",
    "base_glob_Cos_performance_LR = {\"AUPRC\": [], \"AUROC\": []}\n",
    "for k in tqdm(k_sizes_test):\n",
    "    base_AUPRC_glob_KNN, base_AUROC_glob_KNN = KNN(glob_Cos_idx_y_dict_test, k, y_test)\n",
    "    base_glob_Cos_performance_KNN[\"AUPRC\"].append(base_AUPRC_glob_KNN)\n",
    "    base_glob_Cos_performance_KNN[\"AUROC\"].append(base_AUROC_glob_KNN)\n",
    "    base_AUPRC_glob_LR, base_AUROC_glob_LR = predict_by_LR(X_train, X_test, glob_Cos_idx_y_dict_test, k, y_test)\n",
    "    base_glob_Cos_performance_LR[\"AUPRC\"].append(base_AUPRC_glob_LR)\n",
    "    base_glob_Cos_performance_LR[\"AUROC\"].append(base_AUROC_glob_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Final Performance of Personalized Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save results\n",
    "# List of dictionaries and their desired filenames\n",
    "dicts_to_save = {\n",
    "    \"base_glob_Euc_performance_KNN\": base_glob_Euc_performance_KNN,\n",
    "    \"base_glob_Cos_performance_KNN\": base_glob_Cos_performance_KNN,\n",
    "    \"base_fix_distance_performance_nw_KNN\": base_fix_distance_performance_nw_KNN,\n",
    "    \"base_opt_distance_performance_nw_KNN\": base_opt_distance_performance_nw_KNN,\n",
    "    \"final_model_performance_nw_KNN\": final_model_performance_nw_KNN,\n",
    "    \"final_model_performance_wt_KNN\": final_model_performance_wt_KNN,\n",
    "    \"base_glob_Euc_performance_LR\": base_glob_Euc_performance_LR,\n",
    "    \"base_glob_Cos_performance_LR\": base_glob_Cos_performance_LR,\n",
    "    \"base_fix_distance_performance_nw_LR\": base_fix_distance_performance_nw_LR,\n",
    "    \"base_opt_distance_performance_nw_LR\": base_opt_distance_performance_nw_LR,\n",
    "    \"final_model_performance_nw_LR\": final_model_performance_nw_LR,\n",
    "    \"final_model_performance_wt_LR\": final_model_performance_wt_LR,\n",
    "}\n",
    "\n",
    "# Directory to save the JSON files\n",
    "output_dir = \"./Results_dict/External_validation/\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save each dictionary as a JSON file\n",
    "for filename, data in dicts_to_save.items():\n",
    "    file_path = os.path.join(output_dir, f\"{filename}.json\")\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)  # Use indent=4 for pretty formatting\n",
    "    print(f\"Saved {filename} to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory containing the JSON files\n",
    "input_dir = \"./Results_dict/External_validation/\"\n",
    "\n",
    "# Dictionary to store the loaded data\n",
    "loaded_dicts = {}\n",
    "\n",
    "# Load each JSON file and assign it to the corresponding variable name\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".json\"):  # Process only JSON files\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        variable_name = filename.replace(\".json\", \"\")  # Remove .json to create the variable name\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            globals()[variable_name] = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.Plotting import plot_final_performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(13, 9.5)) \n",
    "\n",
    "plot_final_performance_metrics(axs[0, 0], k_sizes_test, \"AUPRC\", base_glob_Euc_performance_KNN, base_glob_Cos_performance_KNN, base_fix_distance_performance_nw_KNN, base_opt_distance_performance_nw_KNN, final_model_performance_nw_KNN, final_model_performance_wt_KNN, \"KNN\")\n",
    "plot_final_performance_metrics(axs[0, 1], k_sizes_test, \"AUROC\", base_glob_Euc_performance_KNN, base_glob_Cos_performance_KNN, base_fix_distance_performance_nw_KNN, base_opt_distance_performance_nw_KNN, final_model_performance_nw_KNN, final_model_performance_wt_KNN, \"KNN\")\n",
    "plot_final_performance_metrics(axs[1, 0], k_sizes_test, \"AUPRC\", base_glob_Euc_performance_LR, base_glob_Cos_performance_LR, base_fix_distance_performance_nw_LR, base_opt_distance_performance_nw_LR, final_model_performance_nw_LR, final_model_performance_wt_LR, \"Personalized LR\")\n",
    "plot_final_performance_metrics(axs[1, 1], k_sizes_test, \"AUROC\", base_glob_Euc_performance_LR, base_glob_Cos_performance_LR, base_fix_distance_performance_nw_LR, base_opt_distance_performance_nw_LR, final_model_performance_nw_LR, final_model_performance_wt_LR, \"Personalized LR\")\n",
    "add_subplot_index(axs, 2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(fig, figure_folder, \"Final_model_performance_external\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_personalized_modeling",
   "language": "python",
   "name": "aki_personalized_modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
